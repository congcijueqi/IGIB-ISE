{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data from:  1\n",
      "Loaded Data from:  2\n",
      "Loaded Data from:  3\n",
      "X_train shape: (8740, 3, 600)\n",
      "y_train shape: (8740,)\n",
      "X_test shape: (972, 3, 600)\n",
      "y_test shape: (972,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/41: 100%|██████████| 214/214 [00:41<00:00,  5.13batch/s, kl_weight=0.1, loss=1.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41, Loss: 1.8427282397713616, KL Weight: 0.1, Recon Loss: 0.08978283238188128\n",
      "F1 Score: 0.6037341689515603\n",
      "Best model saved with F1 Score: 0.6037341689515603 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/41: 100%|██████████| 214/214 [00:19<00:00, 11.11batch/s, kl_weight=0.2, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/41, Loss: 0.22245526425192289, KL Weight: 0.2, Recon Loss: 0.020214818774887892\n",
      "F1 Score: 0.6052873865579377\n",
      "Best model saved with F1 Score: 0.6052873865579377 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/41: 100%|██████████| 214/214 [00:19<00:00, 10.76batch/s, kl_weight=0.3, loss=0.217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/41, Loss: 0.21678034529507717, KL Weight: 0.3, Recon Loss: 0.010436423582016168\n",
      "F1 Score: 0.6732482542740188\n",
      "Best model saved with F1 Score: 0.6732482542740188 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/41: 100%|██████████| 214/214 [00:19<00:00, 10.91batch/s, kl_weight=0.4, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/41, Loss: 0.19504428000372148, KL Weight: 0.4, Recon Loss: 0.007323026718032137\n",
      "F1 Score: 0.6698880976602238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/41: 100%|██████████| 214/214 [00:23<00:00,  9.15batch/s, kl_weight=0.5, loss=0.181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/41, Loss: 0.18086476763275183, KL Weight: 0.5, Recon Loss: 0.005140207574058707\n",
      "F1 Score: 0.7140663753395535\n",
      "Best model saved with F1 Score: 0.7140663753395535 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/41: 100%|██████████| 214/214 [00:42<00:00,  5.09batch/s, kl_weight=0.6, loss=0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/41, Loss: 0.17239067132506414, KL Weight: 0.6, Recon Loss: 0.002600063535571969\n",
      "F1 Score: 0.7254811036401576\n",
      "Best model saved with F1 Score: 0.7254811036401576 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/41: 100%|██████████| 214/214 [00:19<00:00, 10.81batch/s, kl_weight=0.7, loss=0.166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/41, Loss: 0.1651265188076786, KL Weight: 0.7, Recon Loss: 0.0016729431292129176\n",
      "F1 Score: 0.7220326128175958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/41: 100%|██████████| 214/214 [00:20<00:00, 10.44batch/s, kl_weight=0.8, loss=0.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/41, Loss: 0.15957957290321867, KL Weight: 0.8, Recon Loss: 0.0015022244400162007\n",
      "F1 Score: 0.7503750721292556\n",
      "Best model saved with F1 Score: 0.7503750721292556 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/41: 100%|██████████| 214/214 [00:21<00:00, 10.07batch/s, kl_weight=0.9, loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/41, Loss: 0.15517087628908247, KL Weight: 0.9, Recon Loss: 0.001485395881186335\n",
      "F1 Score: 0.7544222375373306\n",
      "Best model saved with F1 Score: 0.7544222375373306 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/41: 100%|██████████| 214/214 [00:19<00:00, 10.72batch/s, kl_weight=1, loss=0.154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/41, Loss: 0.15233464413714187, KL Weight: 1.0, Recon Loss: 0.001313211606863329\n",
      "F1 Score: 0.7555816686251469\n",
      "Best model saved with F1 Score: 0.7555816686251469 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/41: 100%|██████████| 214/214 [00:20<00:00, 10.68batch/s, kl_weight=1, loss=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/41, Loss: 0.14885449217997979, KL Weight: 1.0, Recon Loss: 0.0012395972297331056\n",
      "F1 Score: 0.7651098901098901\n",
      "Best model saved with F1 Score: 0.7651098901098901 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/41: 100%|██████████| 214/214 [00:19<00:00, 10.94batch/s, kl_weight=1, loss=0.147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/41, Loss: 0.1467670657994034, KL Weight: 1.0, Recon Loss: 0.0011348838386970146\n",
      "F1 Score: 0.7547533092659446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/41: 100%|██████████| 214/214 [00:19<00:00, 10.90batch/s, kl_weight=1, loss=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/41, Loss: 0.1442870909922591, KL Weight: 1.0, Recon Loss: 0.001082408928723623\n",
      "F1 Score: 0.7566718995290423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/41: 100%|██████████| 214/214 [00:19<00:00, 10.81batch/s, kl_weight=1, loss=0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/41, Loss: 0.14179466602122673, KL Weight: 1.0, Recon Loss: 0.0010440721533970612\n",
      "F1 Score: 0.7616237904177484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/41: 100%|██████████| 214/214 [00:22<00:00,  9.73batch/s, kl_weight=1, loss=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/41, Loss: 0.13864554423038092, KL Weight: 1.0, Recon Loss: 0.0010282586271021619\n",
      "F1 Score: 0.7639325189063408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/41: 100%|██████████| 214/214 [00:19<00:00, 10.71batch/s, kl_weight=1, loss=0.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/41, Loss: 0.13824635778910646, KL Weight: 1.0, Recon Loss: 0.0010008637224341455\n",
      "F1 Score: 0.764946764946765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/41: 100%|██████████| 214/214 [00:19<00:00, 10.72batch/s, kl_weight=1, loss=0.136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/41, Loss: 0.13534692277975172, KL Weight: 1.0, Recon Loss: 0.0009454859556112369\n",
      "F1 Score: 0.7536373639809267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/41: 100%|██████████| 214/214 [00:19<00:00, 11.23batch/s, kl_weight=1, loss=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/41, Loss: 0.13315668987615087, KL Weight: 1.0, Recon Loss: 0.0009211634166612698\n",
      "F1 Score: 0.7625933388645253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/41: 100%|██████████| 214/214 [00:19<00:00, 10.77batch/s, kl_weight=1, loss=0.131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/41, Loss: 0.13121189647049547, KL Weight: 1.0, Recon Loss: 0.0009132333262497124\n",
      "F1 Score: 0.767052767052767\n",
      "Best model saved with F1 Score: 0.767052767052767 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/41: 100%|██████████| 214/214 [00:19<00:00, 10.93batch/s, kl_weight=1, loss=0.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/41, Loss: 0.12907484723864315, KL Weight: 1.0, Recon Loss: 0.00090190511665777\n",
      "F1 Score: 0.7626818020574672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/41: 100%|██████████| 214/214 [00:20<00:00, 10.56batch/s, kl_weight=1, loss=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/41, Loss: 0.1271569448584151, KL Weight: 1.0, Recon Loss: 0.0008974798215731595\n",
      "F1 Score: 0.7581434196396611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/41: 100%|██████████| 214/214 [00:24<00:00,  8.90batch/s, kl_weight=1, loss=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/41, Loss: 0.12581503607123812, KL Weight: 1.0, Recon Loss: 0.0008859405879945294\n",
      "F1 Score: 0.7671676300578034\n",
      "Best model saved with F1 Score: 0.7671676300578034 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/41: 100%|██████████| 214/214 [00:37<00:00,  5.76batch/s, kl_weight=1, loss=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/41, Loss: 0.12237850343373334, KL Weight: 1.0, Recon Loss: 0.0008462339426960936\n",
      "F1 Score: 0.769865597736383\n",
      "Best model saved with F1 Score: 0.769865597736383 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/41: 100%|██████████| 214/214 [00:19<00:00, 10.95batch/s, kl_weight=1, loss=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/41, Loss: 0.12091985142955156, KL Weight: 1.0, Recon Loss: 0.0008541256440672849\n",
      "F1 Score: 0.7709923664122137\n",
      "Best model saved with F1 Score: 0.7709923664122137 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/41: 100%|██████████| 214/214 [00:18<00:00, 11.29batch/s, kl_weight=1, loss=0.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/41, Loss: 0.11951195455600168, KL Weight: 1.0, Recon Loss: 0.0008770960348301401\n",
      "F1 Score: 0.755967224795155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/41: 100%|██████████| 214/214 [00:19<00:00, 10.73batch/s, kl_weight=1, loss=0.119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/41, Loss: 0.11854949398575543, KL Weight: 1.0, Recon Loss: 0.0008651116595246663\n",
      "F1 Score: 0.7758462946020128\n",
      "Best model saved with F1 Score: 0.7758462946020128 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/41: 100%|██████████| 214/214 [00:20<00:00, 10.49batch/s, kl_weight=1, loss=0.118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/41, Loss: 0.11842268169204766, KL Weight: 1.0, Recon Loss: 0.000850560431364297\n",
      "F1 Score: 0.7684100661022846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/41: 100%|██████████| 214/214 [00:18<00:00, 11.66batch/s, kl_weight=1, loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/41, Loss: 0.11472476378222492, KL Weight: 1.0, Recon Loss: 0.0008691812040736882\n",
      "F1 Score: 0.7729232203192357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/41: 100%|██████████| 214/214 [00:20<00:00, 10.49batch/s, kl_weight=1, loss=0.113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/41, Loss: 0.11295928377832208, KL Weight: 1.0, Recon Loss: 0.0008120936451471089\n",
      "F1 Score: 0.7764705882352941\n",
      "Best model saved with F1 Score: 0.7764705882352941 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/41: 100%|██████████| 214/214 [00:21<00:00, 10.15batch/s, kl_weight=1, loss=0.113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/41, Loss: 0.11230519351279625, KL Weight: 1.0, Recon Loss: 0.0008189267120933351\n",
      "F1 Score: 0.7756432646408197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/41: 100%|██████████| 214/214 [00:20<00:00, 10.20batch/s, kl_weight=1, loss=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/41, Loss: 0.11095400635048608, KL Weight: 1.0, Recon Loss: 0.0008318326966380091\n",
      "F1 Score: 0.7787610619469026\n",
      "Best model saved with F1 Score: 0.7787610619469026 at /home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/41: 100%|██████████| 214/214 [00:33<00:00,  6.42batch/s, kl_weight=1, loss=0.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/41, Loss: 0.10965102810029671, KL Weight: 1.0, Recon Loss: 0.0008155837419516816\n",
      "F1 Score: 0.7723029658513529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/41: 100%|██████████| 214/214 [00:35<00:00,  5.99batch/s, kl_weight=1, loss=0.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/41, Loss: 0.10952699111304551, KL Weight: 1.0, Recon Loss: 0.0008277536917120984\n",
      "F1 Score: 0.7723369691343699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/41: 100%|██████████| 214/214 [00:35<00:00,  6.07batch/s, kl_weight=1, loss=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/41, Loss: 0.10822168678463062, KL Weight: 1.0, Recon Loss: 0.0007802124984375262\n",
      "F1 Score: 0.7693389592123769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/41: 100%|██████████| 214/214 [00:34<00:00,  6.25batch/s, kl_weight=1, loss=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/41, Loss: 0.10519002827110692, KL Weight: 1.0, Recon Loss: 0.0007920977281445689\n",
      "F1 Score: 0.7777006708304418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/41: 100%|██████████| 214/214 [00:22<00:00,  9.64batch/s, kl_weight=1, loss=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/41, Loss: 0.10402593176777118, KL Weight: 1.0, Recon Loss: 0.0007994765011598051\n",
      "F1 Score: 0.766903073286052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/41: 100%|██████████| 214/214 [00:19<00:00, 10.97batch/s, kl_weight=1, loss=0.104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/41, Loss: 0.10391852506828085, KL Weight: 1.0, Recon Loss: 0.0008202914546230791\n",
      "F1 Score: 0.7774071091682964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/41: 100%|██████████| 214/214 [00:21<00:00, 10.15batch/s, kl_weight=1, loss=0.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/41, Loss: 0.10151361520880851, KL Weight: 1.0, Recon Loss: 0.0007852204167120872\n",
      "F1 Score: 0.7787528868360277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/41: 100%|██████████| 214/214 [00:19<00:00, 10.89batch/s, kl_weight=1, loss=0.1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/41, Loss: 0.09985604419190193, KL Weight: 1.0, Recon Loss: 0.0007848216685309797\n",
      "F1 Score: 0.7705184840734712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/41: 100%|██████████| 214/214 [00:19<00:00, 10.89batch/s, kl_weight=1, loss=0.1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/41, Loss: 0.1003656875446578, KL Weight: 1.0, Recon Loss: 0.0007883615206457048\n",
      "F1 Score: 0.7697383926467122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/41: 100%|██████████| 214/214 [00:19<00:00, 10.92batch/s, kl_weight=1, loss=0.0988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/41, Loss: 0.09880477861962586, KL Weight: 1.0, Recon Loss: 0.0007757751350552192\n",
      "F1 Score: 0.7682613768961494\n",
      "F1 Score: 0.7682613768961494\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from scipy.interpolate import interp1d\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Disable RDLogger warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import os\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "functional_groups = {\n",
    "    'Acid anhydride': Chem.MolFromSmarts('[CX3](=[OX1])[OX2][CX3](=[OX1])'),\n",
    "    'Acyl halide': Chem.MolFromSmarts('[CX3](=[OX1])[F,Cl,Br,I]'),\n",
    "    'Alcohol': Chem.MolFromSmarts('[#6][OX2H]'),\n",
    "    'Aldehyde': Chem.MolFromSmarts('[CX3H1](=O)[#6,H]'),\n",
    "    'Alkane': Chem.MolFromSmarts('[CX4;H3,H2]'),\n",
    "    'Alkene': Chem.MolFromSmarts('[CX3]=[CX3]'),\n",
    "    'Alkyne': Chem.MolFromSmarts('[CX2]#[CX2]'),\n",
    "    'Amide': Chem.MolFromSmarts('[NX3][CX3](=[OX1])[#6]'),\n",
    "    'Amine': Chem.MolFromSmarts('[NX3;H2,H1,H0;!$(NC=O)]'),\n",
    "    'Arene': Chem.MolFromSmarts('[cX3]1[cX3][cX3][cX3][cX3][cX3]1'),\n",
    "    'Azo compound': Chem.MolFromSmarts('[#6][NX2]=[NX2][#6]'),\n",
    "    'Carbamate': Chem.MolFromSmarts('[NX3][CX3](=[OX1])[OX2H0]'),\n",
    "    'Carboxylic acid': Chem.MolFromSmarts('[CX3](=O)[OX2H]'),\n",
    "    'Enamine': Chem.MolFromSmarts('[NX3][CX3]=[CX3]'),\n",
    "    'Enol': Chem.MolFromSmarts('[OX2H][#6X3]=[#6]'),\n",
    "    'Ester': Chem.MolFromSmarts('[#6][CX3](=O)[OX2H0][#6]'),\n",
    "    'Ether': Chem.MolFromSmarts('[OD2]([#6])[#6]'),\n",
    "    'Haloalkane': Chem.MolFromSmarts('[#6][F,Cl,Br,I]'),\n",
    "    'Hydrazine': Chem.MolFromSmarts('[NX3][NX3]'),\n",
    "    'Hydrazone': Chem.MolFromSmarts('[NX3][NX2]=[#6]'),\n",
    "    'Imide': Chem.MolFromSmarts('[CX3](=[OX1])[NX3][CX3](=[OX1])'),\n",
    "    'Imine': Chem.MolFromSmarts('[$([CX3]([#6])[#6]),$([CX3H][#6])]=[$([NX2][#6]),$([NX2H])]'),\n",
    "    'Isocyanate': Chem.MolFromSmarts('[NX2]=[C]=[O]'),\n",
    "    'Isothiocyanate': Chem.MolFromSmarts('[NX2]=[C]=[S]'),\n",
    "    'Ketone': Chem.MolFromSmarts('[#6][CX3](=O)[#6]'),\n",
    "    'Nitrile': Chem.MolFromSmarts('[NX1]#[CX2]'),\n",
    "    'Phenol': Chem.MolFromSmarts('[OX2H][cX3]:[c]'),\n",
    "    'Phosphine': Chem.MolFromSmarts('[PX3]'),\n",
    "    'Sulfide': Chem.MolFromSmarts('[#16X2H0]'),\n",
    "    'Sulfonamide': Chem.MolFromSmarts('[#16X4]([NX3])(=[OX1])(=[OX1])[#6]'),\n",
    "    'Sulfonate': Chem.MolFromSmarts('[#16X4](=[OX1])(=[OX1])([#6])[OX2H0]'),\n",
    "    'Sulfone': Chem.MolFromSmarts('[#16X4](=[OX1])(=[OX1])([#6])[#6]'),\n",
    "    'Sulfonic acid': Chem.MolFromSmarts('[#16X4](=[OX1])(=[OX1])([#6])[OX2H]'),\n",
    "    'Sulfoxide': Chem.MolFromSmarts('[#16X3]=[OX1]'),\n",
    "    'Thial': Chem.MolFromSmarts('[CX3H1](=S)[#6,H]'),\n",
    "    'Thioamide': Chem.MolFromSmarts('[NX3][CX3]=[SX1]'),\n",
    "    'Thiol': Chem.MolFromSmarts('[#16X2H]')\n",
    "}\n",
    "def match_group(mol: Chem.Mol, func_group) -> int:\n",
    "    if type(func_group) == Chem.Mol:\n",
    "        n = len(mol.GetSubstructMatches(func_group))\n",
    "    else:\n",
    "        n = func_group(mol)\n",
    "    return 0 if n == 0 else 1\n",
    "# Function to map SMILES to functional groups (no change)\n",
    "def get_functional_groups(smiles: str) -> dict:\n",
    "    smiles = smiles.strip().replace(' ', '')\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: \n",
    "        return None\n",
    "    func_groups = [match_group(mol, smarts) for smarts in functional_groups.values()]\n",
    "    return func_groups\n",
    "\n",
    "def interpolate_to_600(spec):\n",
    "    old_x = np.arange(len(spec))\n",
    "    new_x = np.linspace(min(old_x), max(old_x), 600)\n",
    "    interp = interp1d(old_x, spec)\n",
    "    return interp(new_x)\n",
    "\n",
    "def make_msms_spectrum(spectrum):\n",
    "    msms_spectrum = np.zeros(10000)\n",
    "    for peak in spectrum:\n",
    "        peak_pos = int(peak[0]*10)\n",
    "        peak_pos = min(peak_pos, 9999)\n",
    "        msms_spectrum[peak_pos] = peak[1]\n",
    "    return msms_spectrum\n",
    "\n",
    "# Define CNN Model in PyTo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "'''\n",
    "class IndependentCNN(nn.Module):\n",
    "    def __init__(self, num_fgs):\n",
    "        super(IndependentCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=31, kernel_size=11, padding='same')\n",
    "        self.conv2 = nn.Conv1d(in_channels=31, out_channels=62, kernel_size=11, padding='same')\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(31)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(62)\n",
    "\n",
    "        # MLP for selecting important channels (62 channels)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(62, 128),  # Input 150 features per channel\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)     # Output importance score for each channel\n",
    "        )\n",
    "    def compress(self, solute_features):\n",
    "    \n",
    "        p = self.mlp(solute_features)\n",
    "        device = solute_features.device\n",
    "        temperature = 1.0\n",
    "        bias = 0.0 + 0.0001  # If bias is 0, we run into problems\n",
    "        eps = (bias - (1 - bias)) * torch.rand(p.size()) + (1 - bias)\n",
    "        gate_inputs = torch.log(eps) - torch.log(1 - eps)\n",
    "        gate_inputs = gate_inputs.to(device)\n",
    "        gate_inputs = (gate_inputs + p) / temperature\n",
    "        gate_inputs = torch.sigmoid(gate_inputs).squeeze()\n",
    "        p =torch.sigmoid(p)\n",
    "        return gate_inputs,p\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = F.max_pool1d(x, 1)\n",
    "        x = F.relu(self.batch_norm2(self.conv2(x)))\n",
    "        x = F.max_pool1d(x, 4)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # 通道重要性计算(这里对通道的重要性计算应该改成对频率的重要性计算，这样才能算采样。)（那就是先）\n",
    "        #其实，光谱应该剩下的补充0，而不是补充均值补充均值是没有道理的。\n",
    "        static_feature_map = x.clone().detach()\n",
    "        channel_means = x.mean(dim=1)\n",
    "        channel_std = x.std(dim=1)\n",
    "\n",
    "        channel_importance,p = self.compress(x)\n",
    "        #print(channel_importance.size())#41,150\n",
    "        channel_importance=channel_importance.unsqueeze(-1)\n",
    "        ib_x_mean = x * channel_importance + (1 - channel_importance) * channel_means.unsqueeze(1)\n",
    "        ib_x_std = (1 - channel_importance) * channel_std.unsqueeze(1)\n",
    "        ib_x = ib_x_mean + torch.rand_like(ib_x_mean) * ib_x_std\n",
    "\n",
    "        # KL Divergence loss\n",
    "        epsilon = 1e-8\n",
    "        KL_tensor = 0.5 * (\n",
    "            (ib_x_std**2) / (channel_std.unsqueeze(1) + epsilon)**2 +\n",
    "            (channel_std.unsqueeze(1)**2) / (ib_x_std + epsilon)**2 - 1\n",
    "        ) + ((ib_x_mean - channel_means.unsqueeze(1))**2) / (channel_std.unsqueeze(1) + epsilon)**2\n",
    "\n",
    "        KL_Loss = torch.mean(KL_tensor)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        ib_x = ib_x.permute(0, 2, 1)\n",
    "        return ib_x, KL_Loss,p\n",
    "\n",
    "'''\n",
    "\n",
    "class IndependentCNN(nn.Module):\n",
    "    def __init__(self, num_fgs):\n",
    "        super(IndependentCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=11, padding='same')\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=11, padding='same')\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "\n",
    "        # MLP for selecting important channels (62 channels)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(128, 256),  # 输入每个通道150个特征\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)     # 输出每个通道的重要性评分\n",
    "        )\n",
    "\n",
    "    def compress(self, solute_features):\n",
    "        p = self.mlp(solute_features)\n",
    "        device = solute_features.device\n",
    "        temperature = 1.0\n",
    "        bias = 0.0001  # 避免 bias 为 0 导致的问题\n",
    "        eps = (bias - (1 - bias)) * torch.rand(p.size()) + (1 - bias)\n",
    "        gate_inputs = torch.log(eps) - torch.log(1 - eps)\n",
    "        gate_inputs = gate_inputs.to(device)\n",
    "        gate_inputs = (gate_inputs + p) / temperature\n",
    "        #gate_inputs = (p) / temperature\n",
    "        gate_inputs = torch.sigmoid(gate_inputs).squeeze()\n",
    "        p = torch.sigmoid(p)\n",
    "        return gate_inputs, p\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 卷积与批归一化\n",
    "        x = F.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = F.max_pool1d(x, 2)  # 池化大小为1，不改变尺寸\n",
    "        x = F.relu(self.batch_norm2(self.conv2(x)))\n",
    "        x = F.max_pool1d(x, 2)  # 池化大小为4，减少特征维度\n",
    "        x = x.permute(0, 2, 1)  # 调整维度顺序\n",
    "\n",
    "        # 复制特征图\n",
    "        static_feature_map = x.clone().detach()\n",
    "        channel_means = x.mean(dim=1)\n",
    "        channel_std = x.std(dim=1)\n",
    "\n",
    "        # 压缩与门控\n",
    "        channel_importance, p = self.compress(x)\n",
    "        channel_importance = channel_importance.unsqueeze(-1)\n",
    "\n",
    "        # **修改部分开始**\n",
    "        # 将不重要的部分置为0，而不是均值\n",
    "        ib_x_mean = x * channel_importance  # 去除 (1 - channel_importance) * channel_means.unsqueeze(1)\n",
    "        ib_x_std = (1 - channel_importance) * channel_std.unsqueeze(1)\n",
    "        ib_x = ib_x_mean + torch.rand_like(ib_x_mean) * ib_x_std\n",
    "        # **修改部分结束**\n",
    "\n",
    "        # KL 散度损失计算\n",
    "        epsilon = 1e-8\n",
    "        KL_tensor = 0.5 * (\n",
    "            (ib_x_std**2) / (channel_std.unsqueeze(1) + epsilon)**2 +\n",
    "            (channel_std.unsqueeze(1)**2) / (ib_x_std + epsilon)**2 - 1\n",
    "        ) + (ib_x_mean**2) / (channel_std.unsqueeze(1) + epsilon)**2  # 修改了这里，将 (ib_x_mean - 0)**2 替换为 ib_x_mean**2\n",
    "\n",
    "        KL_Loss = torch.mean(KL_tensor)\n",
    "\n",
    "        # 调整维度顺序并返回\n",
    "        ib_x = ib_x.permute(0, 2, 1)\n",
    "        return ib_x, KL_Loss, p\n",
    "\n",
    "\n",
    "\n",
    "def rbf_kernel(x, y, sigma=1.0):\n",
    "    \"\"\"\n",
    "    x: [B, D]\n",
    "    y: [B, D]\n",
    "    sigma: RBF 核的带宽 (可调)\n",
    "    返回: [B, B] 的核矩阵\n",
    "    \"\"\"\n",
    "    # x.unsqueeze(1): [B, 1, D]\n",
    "    # y.unsqueeze(0): [1, B, D]\n",
    "    # dist: [B, B]，表示 x_i 与 y_j 的欧式距离平方\n",
    "    x = x.unsqueeze(1)\n",
    "    y = y.unsqueeze(0)\n",
    "    dist = (x - y).pow(2).sum(dim=2)\n",
    "    kxy = torch.exp(-dist / (2 * sigma**2))\n",
    "    return kxy\n",
    "\n",
    "# =============== 2. 定义 HSIC 计算函数 ===============\n",
    "def hsic(x, y, sigma=1.0):\n",
    "    \"\"\"\n",
    "    计算 x, y 的 HSIC 值: HSIC(X, Y) = 1/(n-1)^2 * Tr(H Kx H Ky)\n",
    "    x: [B, D]\n",
    "    y: [B, D]\n",
    "    sigma: RBF 核带宽\n",
    "    返回标量 HSIC 值\n",
    "    \"\"\"\n",
    "    assert x.size(0) == y.size(0), \"x,y 的 batch size 不一致\"\n",
    "    n = x.size(0)\n",
    "\n",
    "    # 计算核矩阵\n",
    "    Kx = rbf_kernel(x, x, sigma=sigma)\n",
    "    Ky = rbf_kernel(y, y, sigma=sigma)\n",
    "\n",
    "    # 居中矩阵 H = I - 1/n\n",
    "    H = torch.eye(n, device=x.device) - (1./n) * torch.ones((n, n), device=x.device)\n",
    "\n",
    "    # H Kx H\n",
    "    HKxH = H.mm(Kx).mm(H)\n",
    "\n",
    "    # HSIC = Tr( (H Kx H) * Ky ) / (n-1)^2\n",
    "    # 注: 这里相乘可以写为 trace(HKxH @ Ky)，矩阵乘法后再 trace\n",
    "    hsic_val = torch.trace(HKxH.mm(Ky)) / (float(n - 1) ** 2)\n",
    "\n",
    "    return hsic_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModelWithVAE(nn.Module): \n",
    "    def __init__(self, num_fgs, channel=128, feature_dim=150, hidden_dim=256, latent_dim=64, m_dim=10):\n",
    "        \"\"\"\n",
    "        参数：\n",
    "        - num_fgs: 预测目标的维度\n",
    "        - channel: 每个光谱的通道数（不同频率段）\n",
    "        - feature_dim: 每个光谱的特征维度\n",
    "        - hidden_dim: 隐藏层维度\n",
    "        - latent_dim: 潜在变量 z 的维度\n",
    "        - m_dim: 预测目标的维度（如有需要）\n",
    "        \"\"\"\n",
    "        super(CNNModelWithVAE, self).__init__()\n",
    "        self.channel = channel\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "        # 创建三个独立的CNN模块\n",
    "        self.cnn1 = IndependentCNN(num_fgs)\n",
    "        self.cnn2 = IndependentCNN(num_fgs)\n",
    "        self.cnn3 = IndependentCNN(num_fgs)\n",
    "\n",
    "\n",
    "        # VAE Encoder: 将三个光谱特征融合成潜在表示 z\n",
    "        # 将 [B, 3*channel, feature_dim] 展平为 [B, 3*channel*feature_dim]\n",
    "        self.fc_fusion = nn.Sequential(\n",
    "            nn.Linear(3 * channel * feature_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # VAE Decoder: 从潜在表示 z 重建三个光谱\n",
    "        self.decoder = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(latent_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, channel * feature_dim),\n",
    "                nn.ReLU()\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "\n",
    "\n",
    "        # 增加一个线性层处理 x3 的特征\n",
    "        self.fc_x3 = nn.Linear(channel * feature_dim, latent_dim)\n",
    "\n",
    "        # 全连接层用于最终预测，使用 z 和 x3 作为输入\n",
    "        self.fc1 = nn.Linear(latent_dim *2, 4927)  # z 和 x3\n",
    "        self.fc2 = nn.Linear(4927, 2785)\n",
    "        self.fc3 = nn.Linear(2785, 1574)\n",
    "        self.fc4 = nn.Linear(1574, num_fgs)\n",
    "        self.dropout = nn.Dropout(0.48599073736368)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)   # ~ N(0, I)\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数。\n",
    "        \n",
    "        参数：\n",
    "        - x: 输入张量，形状为 [batch_size, 3, feature_dim]\n",
    "        \n",
    "        返回：\n",
    "        - 一个包含预测结果和各类损失组件的字典\n",
    "        \"\"\"\n",
    "        # 拆分输入为三个光谱通道\n",
    "        x1, x2, x3 = x[:, 0:1, :], x[:, 1:2, :], x[:, 2:3, :]  # 每个 [B, 1, feature_dim]\n",
    "\n",
    "        # 分别通过三个独立的CNN\n",
    "        ib_x_1, kl_loss1,channal_importance_1= self.cnn1(x1)  # [B, channel, feature_dim]\n",
    "        ib_x_2, kl_loss2 ,channal_importance_2= self.cnn2(x2)\n",
    "        ib_x_3, kl_loss3 ,channal_importance_3= self.cnn3(x3)\n",
    "\n",
    "        # 将三个通道的输出堆叠\n",
    "        ib_x_stacked = torch.cat([ib_x_1, ib_x_2, ib_x_3], dim=1)  # [B, 3*channel, feature_dim]\n",
    "        # 展平为 [B, 3*channel*feature_dim]\n",
    "        ib_x_flat = ib_x_stacked.view(ib_x_stacked.size(0), -1)  # [B, 3*channel*feature_dim]\n",
    "        # VAE Encoder\n",
    "        h = self.fc_fusion(ib_x_flat)  # [B, hidden_dim]\n",
    "        mu = self.fc_mu(h)             # [B, latent_dim]\n",
    "        logvar = self.fc_logvar(h)     # [B, latent_dim]\n",
    "        z = self.reparameterize(mu, logvar)  # [B, latent_dim]\n",
    "\n",
    "        # VAE Decoder: 重建三个光谱\n",
    "        recon_x = []\n",
    "        for decoder in self.decoder:\n",
    "            recon = decoder(z)  # [B, channel * feature_dim]\n",
    "            recon = recon.view(z.size(0), self.channel, self.feature_dim)  # [B, channel, feature_dim]\n",
    "            recon_x.append(recon)\n",
    "        recon_x1, recon_x2, recon_x3 = recon_x  # 各自的重构光谱\n",
    "\n",
    "        # 条件互信息估计器\n",
    "        # 将 ib_x_* 展平\n",
    "        ib_x1_flat = ib_x_1.view(z.size(0), -1)  # [B, channel * feature_dim]\n",
    "        ib_x2_flat = ib_x_2.view(z.size(0), -1)\n",
    "        ib_x3_flat = ib_x_3.view(z.size(0), -1)\n",
    "        sigma=1.0\n",
    "        # ====== 3.3 计算 HSIC 并做加和 ======\n",
    "        hsic_x3_x1 = hsic(ib_x3_flat, ib_x1_flat, sigma=sigma)\n",
    "        hsic_x3_x2 = hsic(ib_x3_flat, ib_x2_flat, sigma=sigma)\n",
    "        hsic_x3_z  = hsic(ib_x3_flat, z,     sigma=sigma)\n",
    "\n",
    "        # 将这几个 HSIC 值相加\n",
    "        hsic_loss = hsic_x3_x1 + hsic_x3_x2 + hsic_x3_z\n",
    "\n",
    "        # ====== 3.4 总损失: 主损失 + alpha * HSIC(总和) ======\n",
    "        cmi_loss = hsic_loss\n",
    "\n",
    "        # 增加 x3 的处理\n",
    "        x3_processed = self.fc_x3(ib_x3_flat)  # [B, latent_dim]\n",
    "        z_x3 = torch.cat([z, x3_processed], dim=1)  # [B, 2 * latent_dim]\n",
    "        x_pred = F.relu(self.fc1(z_x3 ))  # [B, 4927]\n",
    "        x_pred = self.dropout(x_pred)\n",
    "        x_pred = F.relu(self.fc2(x_pred))  # [B, 2785]\n",
    "        x_pred = self.dropout(x_pred)\n",
    "        x_pred = F.relu(self.fc3(x_pred))  # [B, 1574]\n",
    "        x_pred = self.dropout(x_pred)\n",
    "        x_pred = torch.sigmoid(self.fc4(x_pred))  # [B, num_fgs]\n",
    "\n",
    "        # KL散度损失取平均值（来自 VAE）\n",
    "        kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
    "        kl=( kl_loss1+ kl_loss2+ kl_loss3)/3\n",
    "        return {\n",
    "            'x': x_pred,\n",
    "            'vae_mu': mu,\n",
    "            'vae_logvar': logvar,\n",
    "            'recon_x1': recon_x1,\n",
    "            'recon_x2': recon_x2,\n",
    "            'recon_x3': recon_x3,\n",
    "            'cmi_loss': cmi_loss,  # InfoNCE 损失\n",
    "            'ib_x_1': ib_x_1,\n",
    "            'ib_x_2': ib_x_2,\n",
    "            'ib_x_3': ib_x_3,\n",
    "            'kl':kl,\n",
    "            'channal_importance_1':channal_importance_1,\n",
    "            'channal_importance_2':channal_importance_2,\n",
    "            'channal_importance_3':channal_importance_3\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "# Training function in PyTorch\n",
    "from tqdm import tqdm  # 引入 tqdm\n",
    "\n",
    "b=0.0001\n",
    "# 定义训练函数\n",
    "# 定义训练函数\n",
    "from tqdm import tqdm  # 引入 tqdm\n",
    "\n",
    "# 定义训练函数\n",
    "def train_model(X_train, y_train, X_test, y_test, num_fgs, weighted=False, batch_size=41, epochs=41, \n",
    "                annealing_epochs=10, max_lambda_kl=1.0, lambda_cmi=0.5, lambda_recon=0.0001):\n",
    "    device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CNNModelWithVAE(num_fgs).to(device)\n",
    "    \n",
    "    # 定义优化器和损失函数\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    if weighted:\n",
    "        class_weights = calculate_class_weights(y_train)\n",
    "        criterion = WeightedBinaryCrossEntropyLoss(class_weights).to(device)\n",
    "    else:\n",
    "        criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    y_train = np.array([np.array(item, dtype=np.float32) for item in y_train], dtype=np.float32)\n",
    "    y_test = np.array([np.array(item, dtype=np.float32) for item in y_test], dtype=np.float32)\n",
    "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 确保保存路径存在\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    best_f1 = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        recon_loss_avg = 0.0\n",
    "        kl_weight = min(max_lambda_kl, (epoch + 1) / annealing_epochs)\n",
    "        with tqdm(train_loader, unit='batch', desc=f\"Epoch {epoch+1}/{epochs}\") as tepoch:\n",
    "            for batch in tepoch:\n",
    "                inputs, targets = batch\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                x_pred = outputs['x']\n",
    "                mu = outputs['vae_mu']\n",
    "                logvar = outputs['vae_logvar']\n",
    "                recon_x1 = outputs['recon_x1']\n",
    "                recon_x2 = outputs['recon_x2']\n",
    "                recon_x3 = outputs['recon_x3']\n",
    "                kl = outputs['kl']\n",
    "                cmi_loss = outputs['cmi_loss']\n",
    "\n",
    "                # 预测损失\n",
    "                pred_loss = criterion(x_pred, targets)\n",
    "                \n",
    "                # 重建损失\n",
    "                recon_loss = F.mse_loss(recon_x1, outputs['ib_x_1']) + \\\n",
    "                             F.mse_loss(recon_x2, outputs['ib_x_2']) + \\\n",
    "                             F.mse_loss(recon_x3, outputs['ib_x_3'])\n",
    "        \n",
    "                # KL散度损失\n",
    "                kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
    "                # 总损失：预测损失 + KL散度 + 互信息损失 + 重建损失\n",
    "                total_loss = pred_loss + kl_weight * kl_div + \\\n",
    "                             lambda_cmi * cmi_loss + lambda_recon * recon_loss + 0.0000001 * kl\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += total_loss.item()\n",
    "                recon_loss_avg += recon_loss.item()\n",
    "                tepoch.set_postfix(loss=running_loss / (tepoch.n + 1),\n",
    "                                  kl_weight=kl_weight)\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        recon_loss_a = recon_loss_avg / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss}, KL Weight: {kl_weight}, Recon Loss: {recon_loss_a}')\n",
    "        \n",
    "        # 评估F1分数\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                x_pred = outputs['x']\n",
    "                predictions.append(x_pred.cpu().numpy())\n",
    "        predictions = np.concatenate(predictions)\n",
    "        binary_predictions = (predictions > 0.5).astype(int)\n",
    "        f1 = f1_score(y_test, binary_predictions, average='micro')\n",
    "        print(f'F1 Score: {f1}')\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            model_save_path = out_path / \"best_model.pth\"\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f'Best model saved with F1 Score: {best_f1} at {model_save_path}')\n",
    "\n",
    "    return binary_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom loss function with class weights\n",
    "class WeightedBinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super(WeightedBinaryCrossEntropyLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = self.class_weights[0] * (1 - y_true) * torch.log(1 - y_pred + 1e-15) + \\\n",
    "               self.class_weights[1] * y_true * torch.log(y_pred + 1e-15)\n",
    "        return -loss.mean()\n",
    "\n",
    "# Calculate class weights\n",
    "def calculate_class_weights(y_true):\n",
    "    num_samples = y_true.shape[0]\n",
    "    class_weights = np.zeros((2, y_true.shape[1]))\n",
    "    for i in range(y_true.shape[1]):\n",
    "        weights_n = num_samples / (2 * (y_true[:, i] == 0).sum())\n",
    "        weights_p = num_samples / (2 * (y_true[:, i] == 1).sum())\n",
    "        class_weights[0, i] = weights_n\n",
    "        class_weights[1, i] = weights_p\n",
    "    return torch.tensor(class_weights.T, dtype=torch.float32)\n",
    "\n",
    "# Loading data (no change)\n",
    "analytical_data = Path(\"/data/zjh2/multimodal-spectroscopic-dataset-main/data/multimodal_spectroscopic_dataset\")\n",
    "out_path = Path(\"/home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all\")\n",
    "columns = [\"h_nmr_spectra\", \"c_nmr_spectra\", \"ir_spectra\"]\n",
    "seed = 3245\n",
    "\n",
    "# 准备存储合并后的数据\n",
    "all_data = []\n",
    "i=0\n",
    "# 一次性读取文件并处理所有列\n",
    "for parquet_file in analytical_data.glob(\"*.parquet\"):\n",
    "    i+=1\n",
    "    # 读取所有需要的列\n",
    "    data = pd.read_parquet(parquet_file, columns=columns + ['smiles'])\n",
    "    \n",
    "    # 对每个列进行插值\n",
    "    for column in columns:\n",
    "        data[column] = data[column].map(interpolate_to_600)\n",
    "    \n",
    "    # 添加功能团信息\n",
    "    data['func_group'] = data.smiles.map(get_functional_groups)\n",
    "    #在这里就是0/1矩阵了\n",
    "    all_data.append(data)\n",
    "    print(f\"Loaded Data from: \", i)\n",
    "    if i==3:\n",
    "        break\n",
    "# 合并所有数据\n",
    "training_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "# 将数据划分为训练集和测试集\n",
    "train, test = train_test_split(training_data, test_size=0.1, random_state=seed)\n",
    "\n",
    "# 定义特征列\n",
    "columns = [\"h_nmr_spectra\", \"c_nmr_spectra\", \"ir_spectra\"]\n",
    "\n",
    "# 提取训练集特征和标签\n",
    "X_train = np.array(train[columns].values.tolist())  # 确保特征值是一个二维数组\n",
    "y_train = np.array(train['func_group'].values)      # 标签转换为一维数组\n",
    "\n",
    "# 提取测试集特征和标签\n",
    "X_test = np.array(test[columns].values.tolist())    # 同样确保二维数组\n",
    "y_test = np.array(test['func_group'].values)        # 标签一维数组\n",
    "\n",
    "# 检查数组形状以验证正确性\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "# Train extended model\n",
    "predictions = train_model(X_train, y_train, X_test, y_test,num_fgs=37, weighted=False, batch_size=41, epochs=41, \n",
    "                annealing_epochs=10, max_lambda_kl=1.0, lambda_cmi=0.1, lambda_recon=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_test = np.array([np.array(item, dtype=np.float32) for item in y_test], dtype=np.float32)\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Save results\n",
    "with open(out_path / \"results.pickle\", \"wb\") as file:\n",
    "    pickle.dump({'pred': predictions, 'tgt': y_test}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data from:  1\n",
      "Loaded Data from:  2\n",
      "Loaded Data from:  3\n",
      "1800\n",
      "[list([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNNModelWithVAE:\n\tMissing key(s) in state_dict: \"cnn1.mlp.0.weight\", \"cnn1.mlp.0.bias\", \"cnn1.mlp.2.weight\", \"cnn1.mlp.2.bias\", \"cnn2.mlp.0.weight\", \"cnn2.mlp.0.bias\", \"cnn2.mlp.2.weight\", \"cnn2.mlp.2.bias\", \"cnn3.mlp.0.weight\", \"cnn3.mlp.0.bias\", \"cnn3.mlp.2.weight\", \"cnn3.mlp.2.bias\". \n\tUnexpected key(s) in state_dict: \"cnn1.mlps.0.0.weight\", \"cnn1.mlps.0.0.bias\", \"cnn1.mlps.0.2.weight\", \"cnn1.mlps.0.2.bias\", \"cnn1.mlps.1.0.weight\", \"cnn1.mlps.1.0.bias\", \"cnn1.mlps.1.2.weight\", \"cnn1.mlps.1.2.bias\", \"cnn1.mlps.2.0.weight\", \"cnn1.mlps.2.0.bias\", \"cnn1.mlps.2.2.weight\", \"cnn1.mlps.2.2.bias\", \"cnn1.mlps.3.0.weight\", \"cnn1.mlps.3.0.bias\", \"cnn1.mlps.3.2.weight\", \"cnn1.mlps.3.2.bias\", \"cnn1.mlps.4.0.weight\", \"cnn1.mlps.4.0.bias\", \"cnn1.mlps.4.2.weight\", \"cnn1.mlps.4.2.bias\", \"cnn1.mlps.5.0.weight\", \"cnn1.mlps.5.0.bias\", \"cnn1.mlps.5.2.weight\", \"cnn1.mlps.5.2.bias\", \"cnn1.mlps.6.0.weight\", \"cnn1.mlps.6.0.bias\", \"cnn1.mlps.6.2.weight\", \"cnn1.mlps.6.2.bias\", \"cnn1.mlps.7.0.weight\", \"cnn1.mlps.7.0.bias\", \"cnn1.mlps.7.2.weight\", \"cnn1.mlps.7.2.bias\", \"cnn1.mlps.8.0.weight\", \"cnn1.mlps.8.0.bias\", \"cnn1.mlps.8.2.weight\", \"cnn1.mlps.8.2.bias\", \"cnn1.mlps.9.0.weight\", \"cnn1.mlps.9.0.bias\", \"cnn1.mlps.9.2.weight\", \"cnn1.mlps.9.2.bias\", \"cnn1.mlps.10.0.weight\", \"cnn1.mlps.10.0.bias\", \"cnn1.mlps.10.2.weight\", \"cnn1.mlps.10.2.bias\", \"cnn1.mlps.11.0.weight\", \"cnn1.mlps.11.0.bias\", \"cnn1.mlps.11.2.weight\", \"cnn1.mlps.11.2.bias\", \"cnn1.mlps.12.0.weight\", \"cnn1.mlps.12.0.bias\", \"cnn1.mlps.12.2.weight\", \"cnn1.mlps.12.2.bias\", \"cnn1.mlps.13.0.weight\", \"cnn1.mlps.13.0.bias\", \"cnn1.mlps.13.2.weight\", \"cnn1.mlps.13.2.bias\", \"cnn1.mlps.14.0.weight\", \"cnn1.mlps.14.0.bias\", \"cnn1.mlps.14.2.weight\", \"cnn1.mlps.14.2.bias\", \"cnn1.mlps.15.0.weight\", \"cnn1.mlps.15.0.bias\", \"cnn1.mlps.15.2.weight\", \"cnn1.mlps.15.2.bias\", \"cnn1.mlps.16.0.weight\", \"cnn1.mlps.16.0.bias\", \"cnn1.mlps.16.2.weight\", \"cnn1.mlps.16.2.bias\", \"cnn1.mlps.17.0.weight\", \"cnn1.mlps.17.0.bias\", \"cnn1.mlps.17.2.weight\", \"cnn1.mlps.17.2.bias\", \"cnn1.mlps.18.0.weight\", \"cnn1.mlps.18.0.bias\", \"cnn1.mlps.18.2.weight\", \"cnn1.mlps.18.2.bias\", \"cnn1.mlps.19.0.weight\", \"cnn1.mlps.19.0.bias\", \"cnn1.mlps.19.2.weight\", \"cnn1.mlps.19.2.bias\", \"cnn1.mlps.20.0.weight\", \"cnn1.mlps.20.0.bias\", \"cnn1.mlps.20.2.weight\", \"cnn1.mlps.20.2.bias\", \"cnn1.mlps.21.0.weight\", \"cnn1.mlps.21.0.bias\", \"cnn1.mlps.21.2.weight\", \"cnn1.mlps.21.2.bias\", \"cnn1.mlps.22.0.weight\", \"cnn1.mlps.22.0.bias\", \"cnn1.mlps.22.2.weight\", \"cnn1.mlps.22.2.bias\", \"cnn1.mlps.23.0.weight\", \"cnn1.mlps.23.0.bias\", \"cnn1.mlps.23.2.weight\", \"cnn1.mlps.23.2.bias\", \"cnn1.mlps.24.0.weight\", \"cnn1.mlps.24.0.bias\", \"cnn1.mlps.24.2.weight\", \"cnn1.mlps.24.2.bias\", \"cnn1.mlps.25.0.weight\", \"cnn1.mlps.25.0.bias\", \"cnn1.mlps.25.2.weight\", \"cnn1.mlps.25.2.bias\", \"cnn1.mlps.26.0.weight\", \"cnn1.mlps.26.0.bias\", \"cnn1.mlps.26.2.weight\", \"cnn1.mlps.26.2.bias\", \"cnn1.mlps.27.0.weight\", \"cnn1.mlps.27.0.bias\", \"cnn1.mlps.27.2.weight\", \"cnn1.mlps.27.2.bias\", \"cnn1.mlps.28.0.weight\", \"cnn1.mlps.28.0.bias\", \"cnn1.mlps.28.2.weight\", \"cnn1.mlps.28.2.bias\", \"cnn1.mlps.29.0.weight\", \"cnn1.mlps.29.0.bias\", \"cnn1.mlps.29.2.weight\", \"cnn1.mlps.29.2.bias\", \"cnn1.mlps.30.0.weight\", \"cnn1.mlps.30.0.bias\", \"cnn1.mlps.30.2.weight\", \"cnn1.mlps.30.2.bias\", \"cnn1.mlps.31.0.weight\", \"cnn1.mlps.31.0.bias\", \"cnn1.mlps.31.2.weight\", \"cnn1.mlps.31.2.bias\", \"cnn1.mlps.32.0.weight\", \"cnn1.mlps.32.0.bias\", \"cnn1.mlps.32.2.weight\", \"cnn1.mlps.32.2.bias\", \"cnn1.mlps.33.0.weight\", \"cnn1.mlps.33.0.bias\", \"cnn1.mlps.33.2.weight\", \"cnn1.mlps.33.2.bias\", \"cnn1.mlps.34.0.weight\", \"cnn1.mlps.34.0.bias\", \"cnn1.mlps.34.2.weight\", \"cnn1.mlps.34.2.bias\", \"cnn1.mlps.35.0.weight\", \"cnn1.mlps.35.0.bias\", \"cnn1.mlps.35.2.weight\", \"cnn1.mlps.35.2.bias\", \"cnn1.mlps.36.0.weight\", \"cnn1.mlps.36.0.bias\", \"cnn1.mlps.36.2.weight\", \"cnn1.mlps.36.2.bias\", \"cnn2.mlps.0.0.weight\", \"cnn2.mlps.0.0.bias\", \"cnn2.mlps.0.2.weight\", \"cnn2.mlps.0.2.bias\", \"cnn2.mlps.1.0.weight\", \"cnn2.mlps.1.0.bias\", \"cnn2.mlps.1.2.weight\", \"cnn2.mlps.1.2.bias\", \"cnn2.mlps.2.0.weight\", \"cnn2.mlps.2.0.bias\", \"cnn2.mlps.2.2.weight\", \"cnn2.mlps.2.2.bias\", \"cnn2.mlps.3.0.weight\", \"cnn2.mlps.3.0.bias\", \"cnn2.mlps.3.2.weight\", \"cnn2.mlps.3.2.bias\", \"cnn2.mlps.4.0.weight\", \"cnn2.mlps.4.0.bias\", \"cnn2.mlps.4.2.weight\", \"cnn2.mlps.4.2.bias\", \"cnn2.mlps.5.0.weight\", \"cnn2.mlps.5.0.bias\", \"cnn2.mlps.5.2.weight\", \"cnn2.mlps.5.2.bias\", \"cnn2.mlps.6.0.weight\", \"cnn2.mlps.6.0.bias\", \"cnn2.mlps.6.2.weight\", \"cnn2.mlps.6.2.bias\", \"cnn2.mlps.7.0.weight\", \"cnn2.mlps.7.0.bias\", \"cnn2.mlps.7.2.weight\", \"cnn2.mlps.7.2.bias\", \"cnn2.mlps.8.0.weight\", \"cnn2.mlps.8.0.bias\", \"cnn2.mlps.8.2.weight\", \"cnn2.mlps.8.2.bias\", \"cnn2.mlps.9.0.weight\", \"cnn2.mlps.9.0.bias\", \"cnn2.mlps.9.2.weight\", \"cnn2.mlps.9.2.bias\", \"cnn2.mlps.10.0.weight\", \"cnn2.mlps.10.0.bias\", \"cnn2.mlps.10.2.weight\", \"cnn2.mlps.10.2.bias\", \"cnn2.mlps.11.0.weight\", \"cnn2.mlps.11.0.bias\", \"cnn2.mlps.11.2.weight\", \"cnn2.mlps.11.2.bias\", \"cnn2.mlps.12.0.weight\", \"cnn2.mlps.12.0.bias\", \"cnn2.mlps.12.2.weight\", \"cnn2.mlps.12.2.bias\", \"cnn2.mlps.13.0.weight\", \"cnn2.mlps.13.0.bias\", \"cnn2.mlps.13.2.weight\", \"cnn2.mlps.13.2.bias\", \"cnn2.mlps.14.0.weight\", \"cnn2.mlps.14.0.bias\", \"cnn2.mlps.14.2.weight\", \"cnn2.mlps.14.2.bias\", \"cnn2.mlps.15.0.weight\", \"cnn2.mlps.15.0.bias\", \"cnn2.mlps.15.2.weight\", \"cnn2.mlps.15.2.bias\", \"cnn2.mlps.16.0.weight\", \"cnn2.mlps.16.0.bias\", \"cnn2.mlps.16.2.weight\", \"cnn2.mlps.16.2.bias\", \"cnn2.mlps.17.0.weight\", \"cnn2.mlps.17.0.bias\", \"cnn2.mlps.17.2.weight\", \"cnn2.mlps.17.2.bias\", \"cnn2.mlps.18.0.weight\", \"cnn2.mlps.18.0.bias\", \"cnn2.mlps.18.2.weight\", \"cnn2.mlps.18.2.bias\", \"cnn2.mlps.19.0.weight\", \"cnn2.mlps.19.0.bias\", \"cnn2.mlps.19.2.weight\", \"cnn2.mlps.19.2.bias\", \"cnn2.mlps.20.0.weight\", \"cnn2.mlps.20.0.bias\", \"cnn2.mlps.20.2.weight\", \"cnn2.mlps.20.2.bias\", \"cnn2.mlps.21.0.weight\", \"cnn2.mlps.21.0.bias\", \"cnn2.mlps.21.2.weight\", \"cnn2.mlps.21.2.bias\", \"cnn2.mlps.22.0.weight\", \"cnn2.mlps.22.0.bias\", \"cnn2.mlps.22.2.weight\", \"cnn2.mlps.22.2.bias\", \"cnn2.mlps.23.0.weight\", \"cnn2.mlps.23.0.bias\", \"cnn2.mlps.23.2.weight\", \"cnn2.mlps.23.2.bias\", \"cnn2.mlps.24.0.weight\", \"cnn2.mlps.24.0.bias\", \"cnn2.mlps.24.2.weight\", \"cnn2.mlps.24.2.bias\", \"cnn2.mlps.25.0.weight\", \"cnn2.mlps.25.0.bias\", \"cnn2.mlps.25.2.weight\", \"cnn2.mlps.25.2.bias\", \"cnn2.mlps.26.0.weight\", \"cnn2.mlps.26.0.bias\", \"cnn2.mlps.26.2.weight\", \"cnn2.mlps.26.2.bias\", \"cnn2.mlps.27.0.weight\", \"cnn2.mlps.27.0.bias\", \"cnn2.mlps.27.2.weight\", \"cnn2.mlps.27.2.bias\", \"cnn2.mlps.28.0.weight\", \"cnn2.mlps.28.0.bias\", \"cnn2.mlps.28.2.weight\", \"cnn2.mlps.28.2.bias\", \"cnn2.mlps.29.0.weight\", \"cnn2.mlps.29.0.bias\", \"cnn2.mlps.29.2.weight\", \"cnn2.mlps.29.2.bias\", \"cnn2.mlps.30.0.weight\", \"cnn2.mlps.30.0.bias\", \"cnn2.mlps.30.2.weight\", \"cnn2.mlps.30.2.bias\", \"cnn2.mlps.31.0.weight\", \"cnn2.mlps.31.0.bias\", \"cnn2.mlps.31.2.weight\", \"cnn2.mlps.31.2.bias\", \"cnn2.mlps.32.0.weight\", \"cnn2.mlps.32.0.bias\", \"cnn2.mlps.32.2.weight\", \"cnn2.mlps.32.2.bias\", \"cnn2.mlps.33.0.weight\", \"cnn2.mlps.33.0.bias\", \"cnn2.mlps.33.2.weight\", \"cnn2.mlps.33.2.bias\", \"cnn2.mlps.34.0.weight\", \"cnn2.mlps.34.0.bias\", \"cnn2.mlps.34.2.weight\", \"cnn2.mlps.34.2.bias\", \"cnn2.mlps.35.0.weight\", \"cnn2.mlps.35.0.bias\", \"cnn2.mlps.35.2.weight\", \"cnn2.mlps.35.2.bias\", \"cnn2.mlps.36.0.weight\", \"cnn2.mlps.36.0.bias\", \"cnn2.mlps.36.2.weight\", \"cnn2.mlps.36.2.bias\", \"cnn3.mlps.0.0.weight\", \"cnn3.mlps.0.0.bias\", \"cnn3.mlps.0.2.weight\", \"cnn3.mlps.0.2.bias\", \"cnn3.mlps.1.0.weight\", \"cnn3.mlps.1.0.bias\", \"cnn3.mlps.1.2.weight\", \"cnn3.mlps.1.2.bias\", \"cnn3.mlps.2.0.weight\", \"cnn3.mlps.2.0.bias\", \"cnn3.mlps.2.2.weight\", \"cnn3.mlps.2.2.bias\", \"cnn3.mlps.3.0.weight\", \"cnn3.mlps.3.0.bias\", \"cnn3.mlps.3.2.weight\", \"cnn3.mlps.3.2.bias\", \"cnn3.mlps.4.0.weight\", \"cnn3.mlps.4.0.bias\", \"cnn3.mlps.4.2.weight\", \"cnn3.mlps.4.2.bias\", \"cnn3.mlps.5.0.weight\", \"cnn3.mlps.5.0.bias\", \"cnn3.mlps.5.2.weight\", \"cnn3.mlps.5.2.bias\", \"cnn3.mlps.6.0.weight\", \"cnn3.mlps.6.0.bias\", \"cnn3.mlps.6.2.weight\", \"cnn3.mlps.6.2.bias\", \"cnn3.mlps.7.0.weight\", \"cnn3.mlps.7.0.bias\", \"cnn3.mlps.7.2.weight\", \"cnn3.mlps.7.2.bias\", \"cnn3.mlps.8.0.weight\", \"cnn3.mlps.8.0.bias\", \"cnn3.mlps.8.2.weight\", \"cnn3.mlps.8.2.bias\", \"cnn3.mlps.9.0.weight\", \"cnn3.mlps.9.0.bias\", \"cnn3.mlps.9.2.weight\", \"cnn3.mlps.9.2.bias\", \"cnn3.mlps.10.0.weight\", \"cnn3.mlps.10.0.bias\", \"cnn3.mlps.10.2.weight\", \"cnn3.mlps.10.2.bias\", \"cnn3.mlps.11.0.weight\", \"cnn3.mlps.11.0.bias\", \"cnn3.mlps.11.2.weight\", \"cnn3.mlps.11.2.bias\", \"cnn3.mlps.12.0.weight\", \"cnn3.mlps.12.0.bias\", \"cnn3.mlps.12.2.weight\", \"cnn3.mlps.12.2.bias\", \"cnn3.mlps.13.0.weight\", \"cnn3.mlps.13.0.bias\", \"cnn3.mlps.13.2.weight\", \"cnn3.mlps.13.2.bias\", \"cnn3.mlps.14.0.weight\", \"cnn3.mlps.14.0.bias\", \"cnn3.mlps.14.2.weight\", \"cnn3.mlps.14.2.bias\", \"cnn3.mlps.15.0.weight\", \"cnn3.mlps.15.0.bias\", \"cnn3.mlps.15.2.weight\", \"cnn3.mlps.15.2.bias\", \"cnn3.mlps.16.0.weight\", \"cnn3.mlps.16.0.bias\", \"cnn3.mlps.16.2.weight\", \"cnn3.mlps.16.2.bias\", \"cnn3.mlps.17.0.weight\", \"cnn3.mlps.17.0.bias\", \"cnn3.mlps.17.2.weight\", \"cnn3.mlps.17.2.bias\", \"cnn3.mlps.18.0.weight\", \"cnn3.mlps.18.0.bias\", \"cnn3.mlps.18.2.weight\", \"cnn3.mlps.18.2.bias\", \"cnn3.mlps.19.0.weight\", \"cnn3.mlps.19.0.bias\", \"cnn3.mlps.19.2.weight\", \"cnn3.mlps.19.2.bias\", \"cnn3.mlps.20.0.weight\", \"cnn3.mlps.20.0.bias\", \"cnn3.mlps.20.2.weight\", \"cnn3.mlps.20.2.bias\", \"cnn3.mlps.21.0.weight\", \"cnn3.mlps.21.0.bias\", \"cnn3.mlps.21.2.weight\", \"cnn3.mlps.21.2.bias\", \"cnn3.mlps.22.0.weight\", \"cnn3.mlps.22.0.bias\", \"cnn3.mlps.22.2.weight\", \"cnn3.mlps.22.2.bias\", \"cnn3.mlps.23.0.weight\", \"cnn3.mlps.23.0.bias\", \"cnn3.mlps.23.2.weight\", \"cnn3.mlps.23.2.bias\", \"cnn3.mlps.24.0.weight\", \"cnn3.mlps.24.0.bias\", \"cnn3.mlps.24.2.weight\", \"cnn3.mlps.24.2.bias\", \"cnn3.mlps.25.0.weight\", \"cnn3.mlps.25.0.bias\", \"cnn3.mlps.25.2.weight\", \"cnn3.mlps.25.2.bias\", \"cnn3.mlps.26.0.weight\", \"cnn3.mlps.26.0.bias\", \"cnn3.mlps.26.2.weight\", \"cnn3.mlps.26.2.bias\", \"cnn3.mlps.27.0.weight\", \"cnn3.mlps.27.0.bias\", \"cnn3.mlps.27.2.weight\", \"cnn3.mlps.27.2.bias\", \"cnn3.mlps.28.0.weight\", \"cnn3.mlps.28.0.bias\", \"cnn3.mlps.28.2.weight\", \"cnn3.mlps.28.2.bias\", \"cnn3.mlps.29.0.weight\", \"cnn3.mlps.29.0.bias\", \"cnn3.mlps.29.2.weight\", \"cnn3.mlps.29.2.bias\", \"cnn3.mlps.30.0.weight\", \"cnn3.mlps.30.0.bias\", \"cnn3.mlps.30.2.weight\", \"cnn3.mlps.30.2.bias\", \"cnn3.mlps.31.0.weight\", \"cnn3.mlps.31.0.bias\", \"cnn3.mlps.31.2.weight\", \"cnn3.mlps.31.2.bias\", \"cnn3.mlps.32.0.weight\", \"cnn3.mlps.32.0.bias\", \"cnn3.mlps.32.2.weight\", \"cnn3.mlps.32.2.bias\", \"cnn3.mlps.33.0.weight\", \"cnn3.mlps.33.0.bias\", \"cnn3.mlps.33.2.weight\", \"cnn3.mlps.33.2.bias\", \"cnn3.mlps.34.0.weight\", \"cnn3.mlps.34.0.bias\", \"cnn3.mlps.34.2.weight\", \"cnn3.mlps.34.2.bias\", \"cnn3.mlps.35.0.weight\", \"cnn3.mlps.35.0.bias\", \"cnn3.mlps.35.2.weight\", \"cnn3.mlps.35.2.bias\", \"cnn3.mlps.36.0.weight\", \"cnn3.mlps.36.0.bias\", \"cnn3.mlps.36.2.weight\", \"cnn3.mlps.36.2.bias\". \n\tsize mismatch for cnn1.conv1.weight: copying a param with shape torch.Size([31, 1, 11]) from checkpoint, the shape in current model is torch.Size([64, 1, 11]).\n\tsize mismatch for cnn1.conv1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.conv2.weight: copying a param with shape torch.Size([62, 31, 11]) from checkpoint, the shape in current model is torch.Size([128, 64, 11]).\n\tsize mismatch for cnn1.conv2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn1.batch_norm1.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.batch_norm1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.batch_norm1.running_mean: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.batch_norm1.running_var: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.batch_norm2.weight: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn1.batch_norm2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn1.batch_norm2.running_mean: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn1.batch_norm2.running_var: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.conv1.weight: copying a param with shape torch.Size([31, 1, 11]) from checkpoint, the shape in current model is torch.Size([64, 1, 11]).\n\tsize mismatch for cnn2.conv1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.conv2.weight: copying a param with shape torch.Size([62, 31, 11]) from checkpoint, the shape in current model is torch.Size([128, 64, 11]).\n\tsize mismatch for cnn2.conv2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.batch_norm1.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.batch_norm1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.batch_norm1.running_mean: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.batch_norm1.running_var: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.batch_norm2.weight: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.batch_norm2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.batch_norm2.running_mean: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.batch_norm2.running_var: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.conv1.weight: copying a param with shape torch.Size([31, 1, 11]) from checkpoint, the shape in current model is torch.Size([64, 1, 11]).\n\tsize mismatch for cnn3.conv1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.conv2.weight: copying a param with shape torch.Size([62, 31, 11]) from checkpoint, the shape in current model is torch.Size([128, 64, 11]).\n\tsize mismatch for cnn3.conv2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.batch_norm1.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.batch_norm1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.batch_norm1.running_mean: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.batch_norm1.running_var: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.batch_norm2.weight: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.batch_norm2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.batch_norm2.running_mean: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.batch_norm2.running_var: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc_fusion.0.weight: copying a param with shape torch.Size([256, 27900]) from checkpoint, the shape in current model is torch.Size([256, 57600]).\n\tsize mismatch for decoder.0.2.weight: copying a param with shape torch.Size([9300, 256]) from checkpoint, the shape in current model is torch.Size([19200, 256]).\n\tsize mismatch for decoder.0.2.bias: copying a param with shape torch.Size([9300]) from checkpoint, the shape in current model is torch.Size([19200]).\n\tsize mismatch for decoder.1.2.weight: copying a param with shape torch.Size([9300, 256]) from checkpoint, the shape in current model is torch.Size([19200, 256]).\n\tsize mismatch for decoder.1.2.bias: copying a param with shape torch.Size([9300]) from checkpoint, the shape in current model is torch.Size([19200]).\n\tsize mismatch for decoder.2.2.weight: copying a param with shape torch.Size([9300, 256]) from checkpoint, the shape in current model is torch.Size([19200, 256]).\n\tsize mismatch for decoder.2.2.bias: copying a param with shape torch.Size([9300]) from checkpoint, the shape in current model is torch.Size([19200]).\n\tsize mismatch for fc_x3.weight: copying a param with shape torch.Size([64, 9300]) from checkpoint, the shape in current model is torch.Size([64, 19200]).\n\tsize mismatch for fc4.weight: copying a param with shape torch.Size([1, 1574]) from checkpoint, the shape in current model is torch.Size([37, 1574]).\n\tsize mismatch for fc4.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([37]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 124\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Train extended model\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m--> 124\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mevalute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43msmiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43mir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_fgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m37\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m                \u001b[49m\u001b[43mannealing_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lambda_kl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_cmi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_recon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m    128\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray(item, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m y_test], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mevalute_model\u001b[0;34m(X_test, y_test, model_path, smiles, ir, num_fgs, weighted, batch_size, annealing_epochs, max_lambda_kl, lambda_cmi, lambda_recon)\u001b[0m\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m CNNModelWithVAE(num_fgs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 创建 DataLoader\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/zs/lib/python3.9/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNNModelWithVAE:\n\tMissing key(s) in state_dict: \"cnn1.mlp.0.weight\", \"cnn1.mlp.0.bias\", \"cnn1.mlp.2.weight\", \"cnn1.mlp.2.bias\", \"cnn2.mlp.0.weight\", \"cnn2.mlp.0.bias\", \"cnn2.mlp.2.weight\", \"cnn2.mlp.2.bias\", \"cnn3.mlp.0.weight\", \"cnn3.mlp.0.bias\", \"cnn3.mlp.2.weight\", \"cnn3.mlp.2.bias\". \n\tUnexpected key(s) in state_dict: \"cnn1.mlps.0.0.weight\", \"cnn1.mlps.0.0.bias\", \"cnn1.mlps.0.2.weight\", \"cnn1.mlps.0.2.bias\", \"cnn1.mlps.1.0.weight\", \"cnn1.mlps.1.0.bias\", \"cnn1.mlps.1.2.weight\", \"cnn1.mlps.1.2.bias\", \"cnn1.mlps.2.0.weight\", \"cnn1.mlps.2.0.bias\", \"cnn1.mlps.2.2.weight\", \"cnn1.mlps.2.2.bias\", \"cnn1.mlps.3.0.weight\", \"cnn1.mlps.3.0.bias\", \"cnn1.mlps.3.2.weight\", \"cnn1.mlps.3.2.bias\", \"cnn1.mlps.4.0.weight\", \"cnn1.mlps.4.0.bias\", \"cnn1.mlps.4.2.weight\", \"cnn1.mlps.4.2.bias\", \"cnn1.mlps.5.0.weight\", \"cnn1.mlps.5.0.bias\", \"cnn1.mlps.5.2.weight\", \"cnn1.mlps.5.2.bias\", \"cnn1.mlps.6.0.weight\", \"cnn1.mlps.6.0.bias\", \"cnn1.mlps.6.2.weight\", \"cnn1.mlps.6.2.bias\", \"cnn1.mlps.7.0.weight\", \"cnn1.mlps.7.0.bias\", \"cnn1.mlps.7.2.weight\", \"cnn1.mlps.7.2.bias\", \"cnn1.mlps.8.0.weight\", \"cnn1.mlps.8.0.bias\", \"cnn1.mlps.8.2.weight\", \"cnn1.mlps.8.2.bias\", \"cnn1.mlps.9.0.weight\", \"cnn1.mlps.9.0.bias\", \"cnn1.mlps.9.2.weight\", \"cnn1.mlps.9.2.bias\", \"cnn1.mlps.10.0.weight\", \"cnn1.mlps.10.0.bias\", \"cnn1.mlps.10.2.weight\", \"cnn1.mlps.10.2.bias\", \"cnn1.mlps.11.0.weight\", \"cnn1.mlps.11.0.bias\", \"cnn1.mlps.11.2.weight\", \"cnn1.mlps.11.2.bias\", \"cnn1.mlps.12.0.weight\", \"cnn1.mlps.12.0.bias\", \"cnn1.mlps.12.2.weight\", \"cnn1.mlps.12.2.bias\", \"cnn1.mlps.13.0.weight\", \"cnn1.mlps.13.0.bias\", \"cnn1.mlps.13.2.weight\", \"cnn1.mlps.13.2.bias\", \"cnn1.mlps.14.0.weight\", \"cnn1.mlps.14.0.bias\", \"cnn1.mlps.14.2.weight\", \"cnn1.mlps.14.2.bias\", \"cnn1.mlps.15.0.weight\", \"cnn1.mlps.15.0.bias\", \"cnn1.mlps.15.2.weight\", \"cnn1.mlps.15.2.bias\", \"cnn1.mlps.16.0.weight\", \"cnn1.mlps.16.0.bias\", \"cnn1.mlps.16.2.weight\", \"cnn1.mlps.16.2.bias\", \"cnn1.mlps.17.0.weight\", \"cnn1.mlps.17.0.bias\", \"cnn1.mlps.17.2.weight\", \"cnn1.mlps.17.2.bias\", \"cnn1.mlps.18.0.weight\", \"cnn1.mlps.18.0.bias\", \"cnn1.mlps.18.2.weight\", \"cnn1.mlps.18.2.bias\", \"cnn1.mlps.19.0.weight\", \"cnn1.mlps.19.0.bias\", \"cnn1.mlps.19.2.weight\", \"cnn1.mlps.19.2.bias\", \"cnn1.mlps.20.0.weight\", \"cnn1.mlps.20.0.bias\", \"cnn1.mlps.20.2.weight\", \"cnn1.mlps.20.2.bias\", \"cnn1.mlps.21.0.weight\", \"cnn1.mlps.21.0.bias\", \"cnn1.mlps.21.2.weight\", \"cnn1.mlps.21.2.bias\", \"cnn1.mlps.22.0.weight\", \"cnn1.mlps.22.0.bias\", \"cnn1.mlps.22.2.weight\", \"cnn1.mlps.22.2.bias\", \"cnn1.mlps.23.0.weight\", \"cnn1.mlps.23.0.bias\", \"cnn1.mlps.23.2.weight\", \"cnn1.mlps.23.2.bias\", \"cnn1.mlps.24.0.weight\", \"cnn1.mlps.24.0.bias\", \"cnn1.mlps.24.2.weight\", \"cnn1.mlps.24.2.bias\", \"cnn1.mlps.25.0.weight\", \"cnn1.mlps.25.0.bias\", \"cnn1.mlps.25.2.weight\", \"cnn1.mlps.25.2.bias\", \"cnn1.mlps.26.0.weight\", \"cnn1.mlps.26.0.bias\", \"cnn1.mlps.26.2.weight\", \"cnn1.mlps.26.2.bias\", \"cnn1.mlps.27.0.weight\", \"cnn1.mlps.27.0.bias\", \"cnn1.mlps.27.2.weight\", \"cnn1.mlps.27.2.bias\", \"cnn1.mlps.28.0.weight\", \"cnn1.mlps.28.0.bias\", \"cnn1.mlps.28.2.weight\", \"cnn1.mlps.28.2.bias\", \"cnn1.mlps.29.0.weight\", \"cnn1.mlps.29.0.bias\", \"cnn1.mlps.29.2.weight\", \"cnn1.mlps.29.2.bias\", \"cnn1.mlps.30.0.weight\", \"cnn1.mlps.30.0.bias\", \"cnn1.mlps.30.2.weight\", \"cnn1.mlps.30.2.bias\", \"cnn1.mlps.31.0.weight\", \"cnn1.mlps.31.0.bias\", \"cnn1.mlps.31.2.weight\", \"cnn1.mlps.31.2.bias\", \"cnn1.mlps.32.0.weight\", \"cnn1.mlps.32.0.bias\", \"cnn1.mlps.32.2.weight\", \"cnn1.mlps.32.2.bias\", \"cnn1.mlps.33.0.weight\", \"cnn1.mlps.33.0.bias\", \"cnn1.mlps.33.2.weight\", \"cnn1.mlps.33.2.bias\", \"cnn1.mlps.34.0.weight\", \"cnn1.mlps.34.0.bias\", \"cnn1.mlps.34.2.weight\", \"cnn1.mlps.34.2.bias\", \"cnn1.mlps.35.0.weight\", \"cnn1.mlps.35.0.bias\", \"cnn1.mlps.35.2.weight\", \"cnn1.mlps.35.2.bias\", \"cnn1.mlps.36.0.weight\", \"cnn1.mlps.36.0.bias\", \"cnn1.mlps.36.2.weight\", \"cnn1.mlps.36.2.bias\", \"cnn2.mlps.0.0.weight\", \"cnn2.mlps.0.0.bias\", \"cnn2.mlps.0.2.weight\", \"cnn2.mlps.0.2.bias\", \"cnn2.mlps.1.0.weight\", \"cnn2.mlps.1.0.bias\", \"cnn2.mlps.1.2.weight\", \"cnn2.mlps.1.2.bias\", \"cnn2.mlps.2.0.weight\", \"cnn2.mlps.2.0.bias\", \"cnn2.mlps.2.2.weight\", \"cnn2.mlps.2.2.bias\", \"cnn2.mlps.3.0.weight\", \"cnn2.mlps.3.0.bias\", \"cnn2.mlps.3.2.weight\", \"cnn2.mlps.3.2.bias\", \"cnn2.mlps.4.0.weight\", \"cnn2.mlps.4.0.bias\", \"cnn2.mlps.4.2.weight\", \"cnn2.mlps.4.2.bias\", \"cnn2.mlps.5.0.weight\", \"cnn2.mlps.5.0.bias\", \"cnn2.mlps.5.2.weight\", \"cnn2.mlps.5.2.bias\", \"cnn2.mlps.6.0.weight\", \"cnn2.mlps.6.0.bias\", \"cnn2.mlps.6.2.weight\", \"cnn2.mlps.6.2.bias\", \"cnn2.mlps.7.0.weight\", \"cnn2.mlps.7.0.bias\", \"cnn2.mlps.7.2.weight\", \"cnn2.mlps.7.2.bias\", \"cnn2.mlps.8.0.weight\", \"cnn2.mlps.8.0.bias\", \"cnn2.mlps.8.2.weight\", \"cnn2.mlps.8.2.bias\", \"cnn2.mlps.9.0.weight\", \"cnn2.mlps.9.0.bias\", \"cnn2.mlps.9.2.weight\", \"cnn2.mlps.9.2.bias\", \"cnn2.mlps.10.0.weight\", \"cnn2.mlps.10.0.bias\", \"cnn2.mlps.10.2.weight\", \"cnn2.mlps.10.2.bias\", \"cnn2.mlps.11.0.weight\", \"cnn2.mlps.11.0.bias\", \"cnn2.mlps.11.2.weight\", \"cnn2.mlps.11.2.bias\", \"cnn2.mlps.12.0.weight\", \"cnn2.mlps.12.0.bias\", \"cnn2.mlps.12.2.weight\", \"cnn2.mlps.12.2.bias\", \"cnn2.mlps.13.0.weight\", \"cnn2.mlps.13.0.bias\", \"cnn2.mlps.13.2.weight\", \"cnn2.mlps.13.2.bias\", \"cnn2.mlps.14.0.weight\", \"cnn2.mlps.14.0.bias\", \"cnn2.mlps.14.2.weight\", \"cnn2.mlps.14.2.bias\", \"cnn2.mlps.15.0.weight\", \"cnn2.mlps.15.0.bias\", \"cnn2.mlps.15.2.weight\", \"cnn2.mlps.15.2.bias\", \"cnn2.mlps.16.0.weight\", \"cnn2.mlps.16.0.bias\", \"cnn2.mlps.16.2.weight\", \"cnn2.mlps.16.2.bias\", \"cnn2.mlps.17.0.weight\", \"cnn2.mlps.17.0.bias\", \"cnn2.mlps.17.2.weight\", \"cnn2.mlps.17.2.bias\", \"cnn2.mlps.18.0.weight\", \"cnn2.mlps.18.0.bias\", \"cnn2.mlps.18.2.weight\", \"cnn2.mlps.18.2.bias\", \"cnn2.mlps.19.0.weight\", \"cnn2.mlps.19.0.bias\", \"cnn2.mlps.19.2.weight\", \"cnn2.mlps.19.2.bias\", \"cnn2.mlps.20.0.weight\", \"cnn2.mlps.20.0.bias\", \"cnn2.mlps.20.2.weight\", \"cnn2.mlps.20.2.bias\", \"cnn2.mlps.21.0.weight\", \"cnn2.mlps.21.0.bias\", \"cnn2.mlps.21.2.weight\", \"cnn2.mlps.21.2.bias\", \"cnn2.mlps.22.0.weight\", \"cnn2.mlps.22.0.bias\", \"cnn2.mlps.22.2.weight\", \"cnn2.mlps.22.2.bias\", \"cnn2.mlps.23.0.weight\", \"cnn2.mlps.23.0.bias\", \"cnn2.mlps.23.2.weight\", \"cnn2.mlps.23.2.bias\", \"cnn2.mlps.24.0.weight\", \"cnn2.mlps.24.0.bias\", \"cnn2.mlps.24.2.weight\", \"cnn2.mlps.24.2.bias\", \"cnn2.mlps.25.0.weight\", \"cnn2.mlps.25.0.bias\", \"cnn2.mlps.25.2.weight\", \"cnn2.mlps.25.2.bias\", \"cnn2.mlps.26.0.weight\", \"cnn2.mlps.26.0.bias\", \"cnn2.mlps.26.2.weight\", \"cnn2.mlps.26.2.bias\", \"cnn2.mlps.27.0.weight\", \"cnn2.mlps.27.0.bias\", \"cnn2.mlps.27.2.weight\", \"cnn2.mlps.27.2.bias\", \"cnn2.mlps.28.0.weight\", \"cnn2.mlps.28.0.bias\", \"cnn2.mlps.28.2.weight\", \"cnn2.mlps.28.2.bias\", \"cnn2.mlps.29.0.weight\", \"cnn2.mlps.29.0.bias\", \"cnn2.mlps.29.2.weight\", \"cnn2.mlps.29.2.bias\", \"cnn2.mlps.30.0.weight\", \"cnn2.mlps.30.0.bias\", \"cnn2.mlps.30.2.weight\", \"cnn2.mlps.30.2.bias\", \"cnn2.mlps.31.0.weight\", \"cnn2.mlps.31.0.bias\", \"cnn2.mlps.31.2.weight\", \"cnn2.mlps.31.2.bias\", \"cnn2.mlps.32.0.weight\", \"cnn2.mlps.32.0.bias\", \"cnn2.mlps.32.2.weight\", \"cnn2.mlps.32.2.bias\", \"cnn2.mlps.33.0.weight\", \"cnn2.mlps.33.0.bias\", \"cnn2.mlps.33.2.weight\", \"cnn2.mlps.33.2.bias\", \"cnn2.mlps.34.0.weight\", \"cnn2.mlps.34.0.bias\", \"cnn2.mlps.34.2.weight\", \"cnn2.mlps.34.2.bias\", \"cnn2.mlps.35.0.weight\", \"cnn2.mlps.35.0.bias\", \"cnn2.mlps.35.2.weight\", \"cnn2.mlps.35.2.bias\", \"cnn2.mlps.36.0.weight\", \"cnn2.mlps.36.0.bias\", \"cnn2.mlps.36.2.weight\", \"cnn2.mlps.36.2.bias\", \"cnn3.mlps.0.0.weight\", \"cnn3.mlps.0.0.bias\", \"cnn3.mlps.0.2.weight\", \"cnn3.mlps.0.2.bias\", \"cnn3.mlps.1.0.weight\", \"cnn3.mlps.1.0.bias\", \"cnn3.mlps.1.2.weight\", \"cnn3.mlps.1.2.bias\", \"cnn3.mlps.2.0.weight\", \"cnn3.mlps.2.0.bias\", \"cnn3.mlps.2.2.weight\", \"cnn3.mlps.2.2.bias\", \"cnn3.mlps.3.0.weight\", \"cnn3.mlps.3.0.bias\", \"cnn3.mlps.3.2.weight\", \"cnn3.mlps.3.2.bias\", \"cnn3.mlps.4.0.weight\", \"cnn3.mlps.4.0.bias\", \"cnn3.mlps.4.2.weight\", \"cnn3.mlps.4.2.bias\", \"cnn3.mlps.5.0.weight\", \"cnn3.mlps.5.0.bias\", \"cnn3.mlps.5.2.weight\", \"cnn3.mlps.5.2.bias\", \"cnn3.mlps.6.0.weight\", \"cnn3.mlps.6.0.bias\", \"cnn3.mlps.6.2.weight\", \"cnn3.mlps.6.2.bias\", \"cnn3.mlps.7.0.weight\", \"cnn3.mlps.7.0.bias\", \"cnn3.mlps.7.2.weight\", \"cnn3.mlps.7.2.bias\", \"cnn3.mlps.8.0.weight\", \"cnn3.mlps.8.0.bias\", \"cnn3.mlps.8.2.weight\", \"cnn3.mlps.8.2.bias\", \"cnn3.mlps.9.0.weight\", \"cnn3.mlps.9.0.bias\", \"cnn3.mlps.9.2.weight\", \"cnn3.mlps.9.2.bias\", \"cnn3.mlps.10.0.weight\", \"cnn3.mlps.10.0.bias\", \"cnn3.mlps.10.2.weight\", \"cnn3.mlps.10.2.bias\", \"cnn3.mlps.11.0.weight\", \"cnn3.mlps.11.0.bias\", \"cnn3.mlps.11.2.weight\", \"cnn3.mlps.11.2.bias\", \"cnn3.mlps.12.0.weight\", \"cnn3.mlps.12.0.bias\", \"cnn3.mlps.12.2.weight\", \"cnn3.mlps.12.2.bias\", \"cnn3.mlps.13.0.weight\", \"cnn3.mlps.13.0.bias\", \"cnn3.mlps.13.2.weight\", \"cnn3.mlps.13.2.bias\", \"cnn3.mlps.14.0.weight\", \"cnn3.mlps.14.0.bias\", \"cnn3.mlps.14.2.weight\", \"cnn3.mlps.14.2.bias\", \"cnn3.mlps.15.0.weight\", \"cnn3.mlps.15.0.bias\", \"cnn3.mlps.15.2.weight\", \"cnn3.mlps.15.2.bias\", \"cnn3.mlps.16.0.weight\", \"cnn3.mlps.16.0.bias\", \"cnn3.mlps.16.2.weight\", \"cnn3.mlps.16.2.bias\", \"cnn3.mlps.17.0.weight\", \"cnn3.mlps.17.0.bias\", \"cnn3.mlps.17.2.weight\", \"cnn3.mlps.17.2.bias\", \"cnn3.mlps.18.0.weight\", \"cnn3.mlps.18.0.bias\", \"cnn3.mlps.18.2.weight\", \"cnn3.mlps.18.2.bias\", \"cnn3.mlps.19.0.weight\", \"cnn3.mlps.19.0.bias\", \"cnn3.mlps.19.2.weight\", \"cnn3.mlps.19.2.bias\", \"cnn3.mlps.20.0.weight\", \"cnn3.mlps.20.0.bias\", \"cnn3.mlps.20.2.weight\", \"cnn3.mlps.20.2.bias\", \"cnn3.mlps.21.0.weight\", \"cnn3.mlps.21.0.bias\", \"cnn3.mlps.21.2.weight\", \"cnn3.mlps.21.2.bias\", \"cnn3.mlps.22.0.weight\", \"cnn3.mlps.22.0.bias\", \"cnn3.mlps.22.2.weight\", \"cnn3.mlps.22.2.bias\", \"cnn3.mlps.23.0.weight\", \"cnn3.mlps.23.0.bias\", \"cnn3.mlps.23.2.weight\", \"cnn3.mlps.23.2.bias\", \"cnn3.mlps.24.0.weight\", \"cnn3.mlps.24.0.bias\", \"cnn3.mlps.24.2.weight\", \"cnn3.mlps.24.2.bias\", \"cnn3.mlps.25.0.weight\", \"cnn3.mlps.25.0.bias\", \"cnn3.mlps.25.2.weight\", \"cnn3.mlps.25.2.bias\", \"cnn3.mlps.26.0.weight\", \"cnn3.mlps.26.0.bias\", \"cnn3.mlps.26.2.weight\", \"cnn3.mlps.26.2.bias\", \"cnn3.mlps.27.0.weight\", \"cnn3.mlps.27.0.bias\", \"cnn3.mlps.27.2.weight\", \"cnn3.mlps.27.2.bias\", \"cnn3.mlps.28.0.weight\", \"cnn3.mlps.28.0.bias\", \"cnn3.mlps.28.2.weight\", \"cnn3.mlps.28.2.bias\", \"cnn3.mlps.29.0.weight\", \"cnn3.mlps.29.0.bias\", \"cnn3.mlps.29.2.weight\", \"cnn3.mlps.29.2.bias\", \"cnn3.mlps.30.0.weight\", \"cnn3.mlps.30.0.bias\", \"cnn3.mlps.30.2.weight\", \"cnn3.mlps.30.2.bias\", \"cnn3.mlps.31.0.weight\", \"cnn3.mlps.31.0.bias\", \"cnn3.mlps.31.2.weight\", \"cnn3.mlps.31.2.bias\", \"cnn3.mlps.32.0.weight\", \"cnn3.mlps.32.0.bias\", \"cnn3.mlps.32.2.weight\", \"cnn3.mlps.32.2.bias\", \"cnn3.mlps.33.0.weight\", \"cnn3.mlps.33.0.bias\", \"cnn3.mlps.33.2.weight\", \"cnn3.mlps.33.2.bias\", \"cnn3.mlps.34.0.weight\", \"cnn3.mlps.34.0.bias\", \"cnn3.mlps.34.2.weight\", \"cnn3.mlps.34.2.bias\", \"cnn3.mlps.35.0.weight\", \"cnn3.mlps.35.0.bias\", \"cnn3.mlps.35.2.weight\", \"cnn3.mlps.35.2.bias\", \"cnn3.mlps.36.0.weight\", \"cnn3.mlps.36.0.bias\", \"cnn3.mlps.36.2.weight\", \"cnn3.mlps.36.2.bias\". \n\tsize mismatch for cnn1.conv1.weight: copying a param with shape torch.Size([31, 1, 11]) from checkpoint, the shape in current model is torch.Size([64, 1, 11]).\n\tsize mismatch for cnn1.conv1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.conv2.weight: copying a param with shape torch.Size([62, 31, 11]) from checkpoint, the shape in current model is torch.Size([128, 64, 11]).\n\tsize mismatch for cnn1.conv2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn1.batch_norm1.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.batch_norm1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.batch_norm1.running_mean: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.batch_norm1.running_var: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn1.batch_norm2.weight: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn1.batch_norm2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn1.batch_norm2.running_mean: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn1.batch_norm2.running_var: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.conv1.weight: copying a param with shape torch.Size([31, 1, 11]) from checkpoint, the shape in current model is torch.Size([64, 1, 11]).\n\tsize mismatch for cnn2.conv1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.conv2.weight: copying a param with shape torch.Size([62, 31, 11]) from checkpoint, the shape in current model is torch.Size([128, 64, 11]).\n\tsize mismatch for cnn2.conv2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.batch_norm1.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.batch_norm1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.batch_norm1.running_mean: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.batch_norm1.running_var: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn2.batch_norm2.weight: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.batch_norm2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.batch_norm2.running_mean: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn2.batch_norm2.running_var: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.conv1.weight: copying a param with shape torch.Size([31, 1, 11]) from checkpoint, the shape in current model is torch.Size([64, 1, 11]).\n\tsize mismatch for cnn3.conv1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.conv2.weight: copying a param with shape torch.Size([62, 31, 11]) from checkpoint, the shape in current model is torch.Size([128, 64, 11]).\n\tsize mismatch for cnn3.conv2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.batch_norm1.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.batch_norm1.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.batch_norm1.running_mean: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.batch_norm1.running_var: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for cnn3.batch_norm2.weight: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.batch_norm2.bias: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.batch_norm2.running_mean: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for cnn3.batch_norm2.running_var: copying a param with shape torch.Size([62]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc_fusion.0.weight: copying a param with shape torch.Size([256, 27900]) from checkpoint, the shape in current model is torch.Size([256, 57600]).\n\tsize mismatch for decoder.0.2.weight: copying a param with shape torch.Size([9300, 256]) from checkpoint, the shape in current model is torch.Size([19200, 256]).\n\tsize mismatch for decoder.0.2.bias: copying a param with shape torch.Size([9300]) from checkpoint, the shape in current model is torch.Size([19200]).\n\tsize mismatch for decoder.1.2.weight: copying a param with shape torch.Size([9300, 256]) from checkpoint, the shape in current model is torch.Size([19200, 256]).\n\tsize mismatch for decoder.1.2.bias: copying a param with shape torch.Size([9300]) from checkpoint, the shape in current model is torch.Size([19200]).\n\tsize mismatch for decoder.2.2.weight: copying a param with shape torch.Size([9300, 256]) from checkpoint, the shape in current model is torch.Size([19200, 256]).\n\tsize mismatch for decoder.2.2.bias: copying a param with shape torch.Size([9300]) from checkpoint, the shape in current model is torch.Size([19200]).\n\tsize mismatch for fc_x3.weight: copying a param with shape torch.Size([64, 9300]) from checkpoint, the shape in current model is torch.Size([64, 19200]).\n\tsize mismatch for fc4.weight: copying a param with shape torch.Size([1, 1574]) from checkpoint, the shape in current model is torch.Size([37, 1574]).\n\tsize mismatch for fc4.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([37])."
     ]
    }
   ],
   "source": [
    "######初始的\n",
    "import matplotlib.pyplot as plt\n",
    "# 定义训练函数\n",
    "def evalute_model(X_test, y_test, model_path,smiles,ir,num_fgs, weighted=False, batch_size=41, \n",
    "                annealing_epochs=10, max_lambda_kl=1.0, lambda_cmi=0.5, lambda_recon=0.1):\n",
    "    device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CNNModelWithVAE(num_fgs).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    # 创建 DataLoader\n",
    "    y_test = np.array([np.array(item, dtype=np.float32) for item in y_test], dtype=np.float32)\n",
    "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "    # 评估F1分数\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            x_pred = outputs['x']\n",
    "            channal_importance_1 = outputs['channal_importance_1']\n",
    "            channal_importance_2 = outputs['channal_importance_2']\n",
    "            channal_importance_3 = outputs['channal_importance_3']\n",
    "            channal_importance_3_cpu = channal_importance_3.squeeze().cpu().numpy()  # squeeze 去除维度 [1, 150, 1] 转为 [150, 1]\n",
    "\n",
    "\n",
    "\n",
    "            # 步骤4: 可视化\n",
    "            plt.plot(np.arange(75), channal_importance_3_cpu)\n",
    "            plt.title(smiles)\n",
    "            plt.xlabel('Wavelength Index')\n",
    "            plt.ylabel('Importance')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            plt.plot(np.arange(1800), ir)\n",
    "            plt.title(smiles)\n",
    "            plt.xlabel('Wavelength Index')\n",
    "            plt.ylabel('ir')\n",
    "            plt.show()\n",
    "            \n",
    "            predictions.append(x_pred.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions)\n",
    "    binary_predictions = (predictions > 0.5).astype(int)\n",
    "    f1 = f1_score(y_test, binary_predictions, average='micro')\n",
    "    print(f'F1 Score: {f1}')\n",
    "\n",
    "    return binary_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom loss function with class weights\n",
    "class WeightedBinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super(WeightedBinaryCrossEntropyLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = self.class_weights[0] * (1 - y_true) * torch.log(1 - y_pred + 1e-15) + \\\n",
    "               self.class_weights[1] * y_true * torch.log(y_pred + 1e-15)\n",
    "        return -loss.mean()\n",
    "\n",
    "# Calculate class weights\n",
    "def calculate_class_weights(y_true):\n",
    "    num_samples = y_true.shape[0]\n",
    "    class_weights = np.zeros((2, y_true.shape[1]))\n",
    "    for i in range(y_true.shape[1]):\n",
    "        weights_n = num_samples / (2 * (y_true[:, i] == 0).sum())\n",
    "        weights_p = num_samples / (2 * (y_true[:, i] == 1).sum())\n",
    "        class_weights[0, i] = weights_n\n",
    "        class_weights[1, i] = weights_p\n",
    "    return torch.tensor(class_weights.T, dtype=torch.float32)\n",
    "\n",
    "# Loading data (no change)\n",
    "analytical_data = Path(\"/data/zjh2/multimodal-spectroscopic-dataset-main/data/multimodal_spectroscopic_dataset\")\n",
    "out_path = Path(\"/home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all\")\n",
    "columns = [\"h_nmr_spectra\", \"c_nmr_spectra\", \"ir_spectra\"]\n",
    "seed = 3245\n",
    "model_path = Path(\"/home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\")\n",
    "# 准备存储合并后的数据\n",
    "all_data = []\n",
    "i=0\n",
    "# 一次性读取文件并处理所有列\n",
    "for parquet_file in analytical_data.glob(\"*.parquet\"):\n",
    "    i+=1\n",
    "    # 读取所有需要的列\n",
    "    data = pd.read_parquet(parquet_file, columns=columns + ['smiles'])\n",
    "    # 对每个列进行插值\n",
    "    for column in columns:\n",
    "        data[column+\"ori\"] = data[column]\n",
    "        data[column] = data[column].map(interpolate_to_600)\n",
    "    \n",
    "    # 添加功能团信息\n",
    "    data['func_group'] = data.smiles.map(get_functional_groups)\n",
    "    #在这里就是0/1矩阵了\n",
    "    all_data.append(data)\n",
    "    print(f\"Loaded Data from: \", i)\n",
    "    if i==3:\n",
    "        break\n",
    "# 合并所有数据\n",
    "training_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "# 将数据划分为训练集和测试集\n",
    "train, test = train_test_split(training_data, test_size=1, random_state=seed)\n",
    "columns = [\"h_nmr_spectra\", \"c_nmr_spectra\", \"ir_spectra\"]\n",
    "\n",
    "\n",
    "# 提取测试集特征和标签\n",
    "X_test = np.array(test[columns].values.tolist())    # 同样确保二维数组\n",
    "y_test = np.array(test['func_group'].values)        # 标签一维数组\n",
    "print(len(test[\"ir_spectraori\"].values.tolist()[0]))\n",
    "smiles = test[\"smiles\"]\n",
    "ir = test[\"ir_spectraori\"].values.tolist()[0]\n",
    "# Train extended model\n",
    "print(test['func_group'].values)\n",
    "predictions = evalute_model( X_test, y_test,model_path,smiles,ir,num_fgs=37, weighted=False, batch_size=1, \n",
    "                annealing_epochs=10, max_lambda_kl=1.0, lambda_cmi=0.1, lambda_recon=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_test = np.array([np.array(item, dtype=np.float32) for item in y_test], dtype=np.float32)\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Save results\n",
    "with open(out_path / \"results.pickle\", \"wb\") as file:\n",
    "    pickle.dump({'pred': predictions, 'tgt': y_test}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data from:  1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m     97\u001b[0m     data[column\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mori\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data[column]\n\u001b[0;32m---> 98\u001b[0m     data[column] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpolate_to_600\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# 添加功能团信息\u001b[39;00m\n\u001b[1;32m    101\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msmiles\u001b[38;5;241m.\u001b[39mmap(get_functional_groups)\n",
      "File \u001b[0;32m~/anaconda3/envs/zs/lib/python3.9/site-packages/pandas/core/series.py:4397\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[1;32m   4319\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4320\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   4321\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4322\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4324\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4325\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4395\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4397\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4399\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4400\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/zs/lib/python3.9/site-packages/pandas/core/base.py:924\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# mapper is a function\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mmap_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[0;32m~/anaconda3/envs/zs/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m, in \u001b[0;36minterpolate_to_600\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterpolate_to_600\u001b[39m(spec):\n\u001b[1;32m     76\u001b[0m     old_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(spec))\n\u001b[0;32m---> 77\u001b[0m     new_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mold_x\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mmax\u001b[39m(old_x), \u001b[38;5;241m600\u001b[39m)\n\u001b[1;32m     78\u001b[0m     interp \u001b[38;5;241m=\u001b[39m interp1d(old_x, spec)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m interp(new_x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######插值600的，插值600和 1800的在图像上是没有区别的。\n",
    "import matplotlib.pyplot as plt\n",
    "# 定义训练函数\n",
    "def evalute_model(X_test, y_test, model_path,smiles,ir,num_fgs, weighted=False, batch_size=41, \n",
    "                annealing_epochs=10, max_lambda_kl=1.0, lambda_cmi=0.5, lambda_recon=0.1):\n",
    "    device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CNNModelWithVAE(num_fgs).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    # 创建 DataLoader\n",
    "    y_test = np.array([np.array(item, dtype=np.float32) for item in y_test], dtype=np.float32)\n",
    "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "    # 评估F1分数\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            x_pred = outputs['x']\n",
    "            channal_importance_1 = outputs['channal_importance_1']\n",
    "            channal_importance_2 = outputs['channal_importance_2']\n",
    "            channal_importance_3 = outputs['channal_importance_3']\n",
    "            channal_importance_3_cpu = channal_importance_3.squeeze().cpu().numpy()  # squeeze 去除维度 [1, 150, 1] 转为 [150, 1]\n",
    "\n",
    "\n",
    "\n",
    "            # 步骤4: 可视化\n",
    "            plt.plot(np.arange(150), channal_importance_3_cpu)\n",
    "            plt.title(smiles)\n",
    "            plt.xlabel('Wavelength Index')\n",
    "            plt.ylabel('Importance')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            plt.plot(np.arange(600), ir)\n",
    "            plt.title(smiles)\n",
    "            plt.xlabel('Wavelength Index')\n",
    "            plt.ylabel('ir')\n",
    "            plt.show()\n",
    "            \n",
    "            predictions.append(x_pred.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions)\n",
    "    binary_predictions = (predictions > 0.5).astype(int)\n",
    "    f1 = f1_score(y_test, binary_predictions, average='micro')\n",
    "    print(f'F1 Score: {f1}')\n",
    "\n",
    "    return binary_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom loss function with class weights\n",
    "class WeightedBinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super(WeightedBinaryCrossEntropyLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = self.class_weights[0] * (1 - y_true) * torch.log(1 - y_pred + 1e-15) + \\\n",
    "               self.class_weights[1] * y_true * torch.log(y_pred + 1e-15)\n",
    "        return -loss.mean()\n",
    "\n",
    "# Calculate class weights\n",
    "def calculate_class_weights(y_true):\n",
    "    num_samples = y_true.shape[0]\n",
    "    class_weights = np.zeros((2, y_true.shape[1]))\n",
    "    for i in range(y_true.shape[1]):\n",
    "        weights_n = num_samples / (2 * (y_true[:, i] == 0).sum())\n",
    "        weights_p = num_samples / (2 * (y_true[:, i] == 1).sum())\n",
    "        class_weights[0, i] = weights_n\n",
    "        class_weights[1, i] = weights_p\n",
    "    return torch.tensor(class_weights.T, dtype=torch.float32)\n",
    "\n",
    "# Loading data (no change)\n",
    "analytical_data = Path(\"/data/zjh2/multimodal-spectroscopic-dataset-main/data/multimodal_spectroscopic_dataset\")\n",
    "out_path = Path(\"/home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all\")\n",
    "columns = [\"h_nmr_spectra\", \"c_nmr_spectra\", \"ir_spectra\"]\n",
    "seed = 3245\n",
    "model_path = Path(\"/home/dwj/icml_guangpu/multimodal-spectroscopic-dataset-main/runs/runs_f_groups/all/best_model.pth\")\n",
    "# 准备存储合并后的数据\n",
    "all_data = []\n",
    "i=0\n",
    "# 一次性读取文件并处理所有列\n",
    "for parquet_file in analytical_data.glob(\"*.parquet\"):\n",
    "    i+=1\n",
    "    # 读取所有需要的列\n",
    "    data = pd.read_parquet(parquet_file, columns=columns + ['smiles'])\n",
    "    # 对每个列进行插值\n",
    "    for column in columns:\n",
    "        data[column+\"ori\"] = data[column]\n",
    "        data[column] = data[column].map(interpolate_to_600)\n",
    "    \n",
    "    # 添加功能团信息\n",
    "    data['func_group'] = data.smiles.map(get_functional_groups)\n",
    "    #在这里就是0/1矩阵了\n",
    "    all_data.append(data)\n",
    "    print(f\"Loaded Data from: \", i)\n",
    "    if i==3:\n",
    "        break\n",
    "# 合并所有数据\n",
    "training_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "# 将数据划分为训练集和测试集\n",
    "train, test = train_test_split(training_data, test_size=1, random_state=seed)\n",
    "columns = [\"h_nmr_spectra\", \"c_nmr_spectra\", \"ir_spectra\"]\n",
    "\n",
    "\n",
    "# 提取测试集特征和标签\n",
    "X_test = np.array(test[columns].values.tolist())    # 同样确保二维数组\n",
    "y_test = np.array(test['func_group'].values)        # 标签一维数组\n",
    "print(len(test[\"ir_spectraori\"].values.tolist()[0]))\n",
    "smiles = test[\"smiles\"]\n",
    "ir = test[\"ir_spectra\"].values.tolist()[0]\n",
    "# Train extended model\n",
    "print(test['func_group'].values)\n",
    "predictions = evalute_model( X_test, y_test,model_path,smiles,ir,num_fgs=37, weighted=False, batch_size=1, \n",
    "                annealing_epochs=10, max_lambda_kl=1.0, lambda_cmi=0.1, lambda_recon=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_test = np.array([np.array(item, dtype=np.float32) for item in y_test], dtype=np.float32)\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Save results\n",
    "with open(out_path / \"results.pickle\", \"wb\") as file:\n",
    "    pickle.dump({'pred': predictions, 'tgt': y_test}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
